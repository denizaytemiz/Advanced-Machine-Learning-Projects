{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c37b4ca7"
      },
      "source": [
        "# Programming Assignment 4: Next-word prediction using LSTM model"
      ],
      "id": "c37b4ca7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "540fff66"
      },
      "source": [
        "In this programming assignment, you will implement `LSTM` to predict the next-word for a given text that come from `imdb_movies_reviews`."
      ],
      "id": "540fff66"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45e8a842"
      },
      "source": [
        "The Goal of this assignment is to:\n",
        "- How to preprocess the data to train a model for next-word prediction.\n",
        "- Build LSTM Unit from scratch and learn about the main component in LSTM unit.\n",
        "- Train and Evaluate the model\n",
        "- Build functions that uses the model for next-word predection\n",
        "- Build function that takes an input as starting point, then use the same model to build a pragraph of n number of words.\n",
        "\n",
        "The structure of the model that you are going to build:"
      ],
      "id": "45e8a842"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72aed94c"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://i.imgur.com/CiQkIFh.png\"/>\n",
        "</div>"
      ],
      "id": "72aed94c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhJ3gacp5dfb"
      },
      "source": [
        "# Important Note: \n",
        "To use the GPU in assignment, you need to enable it first. Here's how you can do it:\n",
        "- Go to the \"Runtime\" menu and select \"Change runtime type\".\n",
        "- In the \"Hardware accelerator\" dropdown, select \"GPU\" and click \"Save\".\n",
        "- Wait for Colab to restart and allocate a GPU to your session.\n",
        "\n",
        "Once you have enabled the GPU, you can check that it's available by running the following: "
      ],
      "id": "IhJ3gacp5dfb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evmAteuE8e0l"
      },
      "source": [
        "\n",
        "<div>\n",
        "<img src=\"https://i.imgur.com/JVsjUgf.png\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://imgur.com/V4RhjD4.png\"/>\n",
        "</div>"
      ],
      "id": "evmAteuE8e0l"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzvTQfrl6BRq",
        "outputId": "29b9c65f-1125-4e14-d05b-516fa8b04543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU is available')\n",
        "else:\n",
        "    print('GPU is not available')"
      ],
      "id": "MzvTQfrl6BRq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d703bf1c"
      },
      "source": [
        "## 1. Load and preprocess data"
      ],
      "id": "d703bf1c"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6a50893d"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import re\n",
        "import math\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.rc('xtick', labelsize=14)\n",
        "matplotlib.rc('ytick', labelsize=14)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "id": "6a50893d"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-4UaJEBq_5O",
        "outputId": "4176dcd6-8fe1-4ec3-9105-7cb6f0b6020f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device"
      ],
      "id": "p-4UaJEBq_5O"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F409qPw6eXJ"
      },
      "source": [
        "## Download and Load the dataset"
      ],
      "id": "7F409qPw6eXJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b8d1479"
      },
      "source": [
        "The data set consists of 40,000 sentences, each labeled '1' (if it came from a positive review) or '-1' (if it came from a negative review). Since the dataset is to large we will use 10,000 sample from the training data for training, and 1000 sample from test data for testing."
      ],
      "id": "7b8d1479"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHb5XAZx3Jdi",
        "outputId": "a26e2ae2-8c8b-489c-8f5d-23655bd17fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-08 16:32:34--  https://github.com/hanialomari/data/raw/main/data.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/hanialomari/data/main/data.zip [following]\n",
            "--2023-04-08 16:32:35--  https://raw.githubusercontent.com/hanialomari/data/main/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5269634 (5.0M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   5.03M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-04-08 16:32:35 (47.3 MB/s) - ‘data.zip’ saved [5269634/5269634]\n",
            "\n",
            "Archive:  data.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: __MACOSX/._test.csv     \n",
            "  inflating: train.csv               \n",
            "  inflating: __MACOSX/._train.csv    \n"
          ]
        }
      ],
      "source": [
        "# Install the dataset\n",
        "!wget https://github.com/hanialomari/data/raw/main/data.zip\n",
        "!unzip data.zip"
      ],
      "id": "qHb5XAZx3Jdi"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0880619e"
      },
      "outputs": [],
      "source": [
        "# read in the IMDB dataset\n",
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')"
      ],
      "id": "0880619e"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "da3cd46c",
        "outputId": "8f682112-81ac-4d9c-e1db-05f7066bc6f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                             review  sentiment\n",
              "0           0  the only entertaining thing that i found about...         -1\n",
              "1           1  i was hoping this would be of the calibre of d...         -1\n",
              "2           2  beyond rangoon is simply marvelous from the tr...          1\n",
              "3           3  this film aka the four hundred blows is a mist...         -1\n",
              "4           4  at times when i watch this movie i start to th...         -1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-757d392c-4ce6-4cc7-81fc-8a3fff7b6b70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>the only entertaining thing that i found about...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>i was hoping this would be of the calibre of d...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>beyond rangoon is simply marvelous from the tr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>this film aka the four hundred blows is a mist...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>at times when i watch this movie i start to th...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-757d392c-4ce6-4cc7-81fc-8a3fff7b6b70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-757d392c-4ce6-4cc7-81fc-8a3fff7b6b70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-757d392c-4ce6-4cc7-81fc-8a3fff7b6b70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# print the first 5 datapoint in the df_train dataframe\n",
        "df_train.head()"
      ],
      "id": "da3cd46c"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "47459fc4",
        "outputId": "2908ba37-4579-4faa-e90b-ae6290f00f7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                             review  sentiment\n",
              "0           0  this flick is sterling example of the state of...          1\n",
              "1           1  it seems like anybody can make a movie nowaday...         -1\n",
              "2           2  this was very good except for two things which...          1\n",
              "3           3  this is highgloss softporn a boring soap opera...         -1\n",
              "4           4  who won the best actress oscar for 1933 it sho...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd4d310e-6b4b-478c-8376-ce50411a4ed8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>this flick is sterling example of the state of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>it seems like anybody can make a movie nowaday...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>this was very good except for two things which...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>this is highgloss softporn a boring soap opera...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>who won the best actress oscar for 1933 it sho...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd4d310e-6b4b-478c-8376-ce50411a4ed8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd4d310e-6b4b-478c-8376-ce50411a4ed8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd4d310e-6b4b-478c-8376-ce50411a4ed8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# print the first 5 datapoint in the df_test dataframe\n",
        "df_test.head()"
      ],
      "id": "47459fc4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5856ef9"
      },
      "source": [
        "### Preprocessing the text data\n",
        "we preprocess text reviews for train and test dataframe by removing punctuations and converting all characters to lower case. The re.sub() method is used to remove punctuations using regular expressions, and lower() method is used to convert all characters to lower case."
      ],
      "id": "e5856ef9"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9f49a5f7"
      },
      "outputs": [],
      "source": [
        "# preprocess the movie review text for train and test\n",
        "df_train['review'] = df_train['review'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x).lower())\n",
        "df_test['review'] = df_test['review'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x).lower())"
      ],
      "id": "9f49a5f7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5447efb"
      },
      "source": [
        "### Tokenize the text data\n",
        "This code is used to tokenize preprocessed text reviews train and test dataframs using the `TreebankWordTokenizer` from the NLTK library. The `apply()` method is used to apply the tokenizer to each element of the column, and the resulting tokenized versions of the reviews are stored in a new column called 'tokens'.\n",
        "\n",
        "Example:\n",
        "\n",
        "'this is a great movie' -- > \t['this', 'is', 'a', 'great', 'movie'] \n",
        "\n",
        "'i didnt like this film at all'  -->   ['i', 'didnt', 'like', 'this', 'film', 'at', 'all']"
      ],
      "id": "a5447efb"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ed42e3ab"
      },
      "outputs": [],
      "source": [
        "# tokenize the preprocessed text for train and test\n",
        "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
        "df_train['tokens'] = df_train['review'].apply(lambda x: tokenizer.tokenize(x))\n",
        "df_test['tokens'] = df_test['review'].apply(lambda x: tokenizer.tokenize(x))"
      ],
      "id": "ed42e3ab"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS4q3GR8TU_j",
        "outputId": "9d7410a0-b783-43a9-a100-98bb7fef2e89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [the, only, entertaining, thing, that, i, foun...\n",
              "1    [i, was, hoping, this, would, be, of, the, cal...\n",
              "2    [beyond, rangoon, is, simply, marvelous, from,...\n",
              "3    [this, film, aka, the, four, hundred, blows, i...\n",
              "4    [at, times, when, i, watch, this, movie, i, st...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#remove this later\n",
        "df_train['tokens'].head()"
      ],
      "id": "SS4q3GR8TU_j"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4481d1c0"
      },
      "source": [
        "#### Create a word ID dictionary:\n",
        "\n",
        "When working with text data, it's often necessary to encode the text into numerical or vector representations to perform mathematical operations on it. One common function for doing this involves creating two dictionaries that map each unique word in a list of tokenized text data to a unique numerical ID and vice versa. To handle out-of-vocabulary words, the <unk> token is added to the word2id dictionary. The resulting dictionaries can be useful for various NLP tasks, such as building a vocabulary for a neural network model.\n",
        "\n",
        "Below is a simple example:\n",
        "\n",
        "data_tokens =  ['this', 'is', 'a', 'great', 'movie'] # a list of tokenized text data\n",
        "\n",
        "word2id =  {'this': 0, 'is': 1, 'a': 2, 'great': 3, 'movie': 4, '<unk>': 5} # a dictionary that maps each unique word in `data_tokens` to a unique numerical ID.\n",
        "\n",
        "id2word = {0: 'this', 1: 'is', 2: 'a', 3: 'great', 4: 'movie', 5: '<unk>'} # a dictionary that maps each numerical ID in the `word2id` dictionary to the corresponding unique word.\n",
        "\n",
        "### Question 1\n",
        "\n",
        "Please write a function that creates two dictionaries to map each unique word in a list of tokenized text data to a numerical ID and vice versa, similar to the example provided. The function should take a list of tokenized text data as input and return two dictionaries: one that maps each unique word to a unique numerical ID, and another that maps each numerical ID to its corresponding unique word. Additionally, the function should include a special <unk> token at the end of the word2id dictionary to handle out-of-vocabulary words that are not present in the original list of tokens.\n",
        "\n",
        "Report the output for the test case below."
      ],
      "id": "4481d1c0"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m6WrSBOYsi8o"
      },
      "outputs": [],
      "source": [
        "def create_word_id_dicts(data_tokens):\n",
        "    \"\"\"\n",
        "    Create two dictionaries to map each unique word to a numerical ID and vice versa.\n",
        "\n",
        "    Args:\n",
        "    - data_tokens (list): A list of tokenized text data (train and test).\n",
        "\n",
        "    Returns:\n",
        "    - word2id (dict): A dictionary that maps each unique word in the input tokens to a unique numerical ID.\n",
        "    - id2word (dict): A dictionary that maps each numerical ID in the `word2id` dictionary to the corresponding unique word.\n",
        "\n",
        "    The function adds a special `<unk>` token at the end of the `word2id` dictionary to handle out-of-vocabulary \n",
        "    words that are not present in the original list of tokens.\n",
        "    \"\"\"\n",
        "    word2id = {}\n",
        "    id2word = {}\n",
        "    ## Student Code here\n",
        "    if isinstance(data_tokens, list):\n",
        "      data_tokens = data_tokens\n",
        "    else:\n",
        "      data_tokens = data_tokens.tolist()\n",
        "    index =  0 \n",
        "    for i in range(len(data_tokens)):\n",
        "      for token in data_tokens[i]:\n",
        "        if token not in word2id:\n",
        "          word2id[token] = index\n",
        "          index = index + 1      \n",
        "    \n",
        "    word2id['<unk>'] = len(word2id) \n",
        "    id2word = {index: token for token , index in word2id.items()}\n",
        "    ##End of the code\n",
        "    return word2id, id2word\n",
        "\n",
        "#The following code creates two dictionaries word2id and id2word that map each unique word \n",
        "# in a concatenated list of tokenized text data to a numerical ID and vice versa, using the \n",
        "# create_word_id_dicts() function. The concatenated list of tokenized text data is created \n",
        "# by merging the tokens columns from two dataframes df_train and df_test using the pd.concat() function.\n",
        "\n",
        "word2id, id2word = create_word_id_dicts(pd.concat([df_train['tokens'],df_test['tokens']])) \n"
      ],
      "id": "m6WrSBOYsi8o"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3lruPjEc3DC",
        "outputId": "673f733a-4c07-4908-a7ea-c77b52240f28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78166"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(word2id.keys())\n"
      ],
      "id": "l3lruPjEc3DC"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z6ujjKMeRQ2",
        "outputId": "6cfa5e4a-7ca2-4aad-f6db-aceebb6e03c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78166"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(id2word.keys())\n"
      ],
      "id": "6Z6ujjKMeRQ2"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3d5b6ee",
        "outputId": "f2aae83c-0270-413c-bee3-c442379d3996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'this': 0, 'is': 1, 'a': 2, 'test': 3, 'case': 4, 'lets': 5, 'try': 6, 'another': 7, 'one': 8, '<unk>': 9}\n",
            "{0: 'this', 1: 'is', 2: 'a', 3: 'test', 4: 'case', 5: 'lets', 6: 'try', 7: 'another', 8: 'one', 9: '<unk>'}\n"
          ]
        }
      ],
      "source": [
        "## Test Case: (Please provide the output of this function in your PDF answer)\n",
        "data_tokens_test_case = [[\"this\", \"is\", \"a\", \"test\", \"case\"], [\"lets\", \"try\", \"another\", \"one\"]]\n",
        "word2id_test_case, id2word_test_case = create_word_id_dicts(data_tokens_test_case)\n",
        "print(word2id_test_case)\n",
        "print(id2word_test_case)\n",
        "\n",
        "### TEST CASE: The output should be like this:\n",
        "\n",
        "##{'this': 0, 'is': 1, 'a': 2, 'test': 3, 'case': 4, 'lets': 5, 'try': 6, 'another': 7, 'one': 8, '<unk>': 9}\n",
        "##{0: 'this', 1: 'is', 2: 'a', 3: 'test', 4: 'case', 5: 'lets', 6: 'try', 7: 'another', 8: 'one', 9: '<unk>'}"
      ],
      "id": "d3d5b6ee"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if2eX1BV6_As",
        "outputId": "d45ff87a-c5d7-4836-998d-2826fe4ec104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'who': 0, 'were': 1, 'they': 2, 'kidding': 3, 'with': 4, 'this': 5, 'there': 6, 'was': 7, 'just': 8, 'too': 9, 'much': 10, 'in': 11, 'film': 12, 'that': 13, 'hard': 14, 'to': 15, 'digest': 16, 'right': 17, 'from': 18, 'when': 19, 'arjun': 20, 'ajay': 21, 'devgan': 22, 'unknowingly': 23, 'wishes': 24, 'death': 25, 'on': 26, 'his': 27, 'father': 28, 'he': 29, 'arrives': 30, 'london': 31, 'uncleplayed': 32, 'by': 33, 'om': 34, 'puri': 35, 'only': 36, 'abandon': 37, 'him': 38, 'minutes': 39, 'later': 40, 'the': 41, 'problem': 42, 'theory': 43, 'is': 44, 'anybody': 45, 'has': 46, 'ever': 47, 'passed': 48, 'through': 49, 'heathrow': 50, 'knows': 51, 'such': 52, 'a': 53, 'fête': 54, 'would': 55, 'be': 56, 'impossible': 57, 'pull': 58, 'off': 59, 'and': 60, 'especially': 61, 'not': 62, 'an': 63, 'indian': 64, 'but': 65, 'problems': 66, 'do': 67, 'end': 68, 'theres': 69, 'issue': 70, 'of': 71, 'two': 72, 'main': 73, 'leads': 74, 'salman': 75, 'khan': 76, 'passing': 77, 'as': 78, 'rockstars': 79, 'verge': 80, 'achieving': 81, 'their': 82, 'dreams': 83, 'i': 84, 'mean': 85, 'yeah': 86, 'we': 87, 'saw': 88, 'success': 89, 'come': 90, 'susan': 91, 'boyle': 92, 'woman': 93, 'uk': 94, 'her': 95, 'after': 96, 'age': 97, '50': 98, 'rare': 99, 'case': 100, 'it': 101, 'really': 102, 'for': 103, 'me': 104, 'suspend': 105, 'my': 106, 'disbelief': 107, 'because': 108, 'felt': 109, 'casting': 110, 'illconceived': 111, 'never': 112, 'cast': 113, 'madhuri': 114, 'dixit': 115, 'sridevi': 116, 'play': 117, 'same': 118, 'roles': 119, 'so': 120, 'why': 121, 'should': 122, 'forced': 123, 'watch': 124, 'men': 125, 'well': 126, 'into': 127, '40s': 128, 'prance': 129, 'around': 130, 'desperately': 131, 'trying': 132, 'hang': 133, '20s': 134, 'lets': 135, 'even': 136, 'talk': 137, 'about': 138, 'most': 139, 'selfconscious': 140, 'actress': 141, 'screen': 142, 'today': 143, 'asin': 144, 'second': 145, 'have': 146, 'seen': 147, 'she': 148, 'hopeless': 149, 'conscious': 150, 'looks': 151, 'concerns': 152, 'herself': 153, 'looking': 154, 'good': 155, 'voguing': 156, 'camera': 157, 'rather': 158, 'than': 159, 'giving': 160, 'acting': 161, 'performance': 162, 'its': 163, 'believe': 164, 'turned': 165, 'down': 166, 'all': 167, 'those': 168, 'other': 169, 'movie': 170, 'star': 171, 'fluff': 172, 'then': 173, 'fluffy': 174, 'nothing': 175, 'write': 176, 'home': 177, 'at': 178, 'top': 179, 'boringly': 180, 'dragged': 181, 'special': 182, 'trust': 183, 'you': 184, 'will': 185, 'predict': 186, 'every': 187, 'clichéd': 188, 'thing': 189, 'going': 190, 'happen': 191, 'instantly': 192, 'fell': 193, 'love': 194, 'pushing': 195, 'daisies': 196, 'show': 197, 'manages': 198, 'put': 199, 'smile': 200, 'face': 201, 'great': 202, 'storytelling': 203, 'witty': 204, 'dialog': 205, 'thats': 206, 'also': 207, 'keep': 208, 'until': 209, 'basic': 210, 'idea': 211, 'behind': 212, 'bringing': 213, 'people': 214, 'back': 215, 'life': 216, 'one': 217, 'touch': 218, 'ending': 219, 'undead': 220, 'status': 221, 'interesting': 222, 'could': 223, 'still': 224, 'seasons': 225, 'suspenseful': 226, 'murder': 227, 'cases': 228, 'unique': 229, 'look': 230, 'highly': 231, 'proficient': 232, 'narrator': 233, 'add': 234, 'experience': 235, 'more': 236, 'parts': 237, 'certain': 238, 'charm': 239, 'enjoy': 240, 'im': 241, 'forward': 242, 'enter': 243, 'world': 244, 'ned': 245, 'chuck': 246, 'season': 247, '<unk>': 248}\n",
            "{0: 'who', 1: 'were', 2: 'they', 3: 'kidding', 4: 'with', 5: 'this', 6: 'there', 7: 'was', 8: 'just', 9: 'too', 10: 'much', 11: 'in', 12: 'film', 13: 'that', 14: 'hard', 15: 'to', 16: 'digest', 17: 'right', 18: 'from', 19: 'when', 20: 'arjun', 21: 'ajay', 22: 'devgan', 23: 'unknowingly', 24: 'wishes', 25: 'death', 26: 'on', 27: 'his', 28: 'father', 29: 'he', 30: 'arrives', 31: 'london', 32: 'uncleplayed', 33: 'by', 34: 'om', 35: 'puri', 36: 'only', 37: 'abandon', 38: 'him', 39: 'minutes', 40: 'later', 41: 'the', 42: 'problem', 43: 'theory', 44: 'is', 45: 'anybody', 46: 'has', 47: 'ever', 48: 'passed', 49: 'through', 50: 'heathrow', 51: 'knows', 52: 'such', 53: 'a', 54: 'fête', 55: 'would', 56: 'be', 57: 'impossible', 58: 'pull', 59: 'off', 60: 'and', 61: 'especially', 62: 'not', 63: 'an', 64: 'indian', 65: 'but', 66: 'problems', 67: 'do', 68: 'end', 69: 'theres', 70: 'issue', 71: 'of', 72: 'two', 73: 'main', 74: 'leads', 75: 'salman', 76: 'khan', 77: 'passing', 78: 'as', 79: 'rockstars', 80: 'verge', 81: 'achieving', 82: 'their', 83: 'dreams', 84: 'i', 85: 'mean', 86: 'yeah', 87: 'we', 88: 'saw', 89: 'success', 90: 'come', 91: 'susan', 92: 'boyle', 93: 'woman', 94: 'uk', 95: 'her', 96: 'after', 97: 'age', 98: '50', 99: 'rare', 100: 'case', 101: 'it', 102: 'really', 103: 'for', 104: 'me', 105: 'suspend', 106: 'my', 107: 'disbelief', 108: 'because', 109: 'felt', 110: 'casting', 111: 'illconceived', 112: 'never', 113: 'cast', 114: 'madhuri', 115: 'dixit', 116: 'sridevi', 117: 'play', 118: 'same', 119: 'roles', 120: 'so', 121: 'why', 122: 'should', 123: 'forced', 124: 'watch', 125: 'men', 126: 'well', 127: 'into', 128: '40s', 129: 'prance', 130: 'around', 131: 'desperately', 132: 'trying', 133: 'hang', 134: '20s', 135: 'lets', 136: 'even', 137: 'talk', 138: 'about', 139: 'most', 140: 'selfconscious', 141: 'actress', 142: 'screen', 143: 'today', 144: 'asin', 145: 'second', 146: 'have', 147: 'seen', 148: 'she', 149: 'hopeless', 150: 'conscious', 151: 'looks', 152: 'concerns', 153: 'herself', 154: 'looking', 155: 'good', 156: 'voguing', 157: 'camera', 158: 'rather', 159: 'than', 160: 'giving', 161: 'acting', 162: 'performance', 163: 'its', 164: 'believe', 165: 'turned', 166: 'down', 167: 'all', 168: 'those', 169: 'other', 170: 'movie', 171: 'star', 172: 'fluff', 173: 'then', 174: 'fluffy', 175: 'nothing', 176: 'write', 177: 'home', 178: 'at', 179: 'top', 180: 'boringly', 181: 'dragged', 182: 'special', 183: 'trust', 184: 'you', 185: 'will', 186: 'predict', 187: 'every', 188: 'clichéd', 189: 'thing', 190: 'going', 191: 'happen', 192: 'instantly', 193: 'fell', 194: 'love', 195: 'pushing', 196: 'daisies', 197: 'show', 198: 'manages', 199: 'put', 200: 'smile', 201: 'face', 202: 'great', 203: 'storytelling', 204: 'witty', 205: 'dialog', 206: 'thats', 207: 'also', 208: 'keep', 209: 'until', 210: 'basic', 211: 'idea', 212: 'behind', 213: 'bringing', 214: 'people', 215: 'back', 216: 'life', 217: 'one', 218: 'touch', 219: 'ending', 220: 'undead', 221: 'status', 222: 'interesting', 223: 'could', 224: 'still', 225: 'seasons', 226: 'suspenseful', 227: 'murder', 228: 'cases', 229: 'unique', 230: 'look', 231: 'highly', 232: 'proficient', 233: 'narrator', 234: 'add', 235: 'experience', 236: 'more', 237: 'parts', 238: 'certain', 239: 'charm', 240: 'enjoy', 241: 'im', 242: 'forward', 243: 'enter', 244: 'world', 245: 'ned', 246: 'chuck', 247: 'season', 248: '<unk>'}\n"
          ]
        }
      ],
      "source": [
        "## Evaluation case: (Please provide the output of this function in your PDF answer)\n",
        "data_tokens_evaluation_case = df_train['tokens'].tolist()[7:9] \n",
        "word2id_test_case, id2word_test_case = create_word_id_dicts(data_tokens_evaluation_case)\n",
        "print(word2id_test_case)\n",
        "print(id2word_test_case)"
      ],
      "id": "if2eX1BV6_As"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2b421a4"
      },
      "source": [
        "### Split tokens into sequences\n",
        "\n",
        "The `split_tokens_into_sequences` function takes in two arguments: `data_tokens`, which is a list of tokenized text data, and `seq_length`, which is an integer representing the length of each sequence.\n",
        "\n",
        "The function initializes an empty list called `sequences` that will store the sequences of tokens. It then iterates through each list of tokens in `data_tokens`. For each list of tokens, the function loops through the list starting at the `seq_length`-th index and ending at the last index.\n",
        "\n",
        "During each iteration of the inner loop, the function creates a sublist of tokens by taking the `seq_length` tokens that immediately precede the current index. This sublist represents a single sequence of tokens. The function then appends this sequence to the `sequences` list.\n",
        "\n",
        "Once the loops are complete, the function returns the `sequences` list, which contains a list of all sequences of `seq_length` tokens that can be created from the input data.\n",
        "\n",
        "For example, if the input `data_tokens` is a list of two sentences: ['The cat sat on the mat', 'The dog ran in the park'], and `seq_length` is set to 4, the function will output a list of sequences:\n",
        "\n",
        "[['The', 'cat', 'sat', 'on'],\n",
        "\n",
        " ['cat', 'sat', 'on', 'the'],\n",
        " \n",
        " ['sat', 'on', 'the', 'mat'],\n",
        " \n",
        " ['The', 'dog', 'ran', 'in'],\n",
        " \n",
        " ['dog', 'ran', 'in', 'the'],\n",
        " \n",
        " ['ran', 'in', 'the', 'park']]\n",
        " \n",
        "#### Question 2 \n",
        "\n",
        "Create the function described above that accepts two arguments: a list of tokenized text data and a sequence length. The function should return a list of sequences where each sequence is a sublist of `data_tokens` with a length of `seq_length`. To achieve this, the function should iterate through each list of tokenized text data and generate sequences of the desired length. Specifically, for each list of tokens, the function should start at the `seq_length`-th token and add the preceding `seq_length` tokens to create the sequence. The function should then append each sequence to the output list called `sequences`."
      ],
      "id": "c2b421a4"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "22e9d2da"
      },
      "outputs": [],
      "source": [
        "def split_tokens_into_sequences(data_tokens, seq_length):\n",
        "    \"\"\"\n",
        "    Split the input list of tokenized text data into sequences of fixed length.\n",
        "\n",
        "    Args:\n",
        "    - data_tokens (list): A list of tokenized text data.\n",
        "    - seq_length (int): The length of each sequence.\n",
        "\n",
        "    Returns:\n",
        "    - sequences (list): A list of sequences of length `seq_length`, where each sequence is a sublist of `data_tokens`.\n",
        "\n",
        "    For each sequence, the function starts at the `seq_length`-th token in the input list of tokens and adds the \n",
        "    preceding `seq_length` tokens to the sequence. The function then appends each sequence to the output list `sequences`.\n",
        "    \"\"\"\n",
        "    sequences = []\n",
        "    # Student Code\n",
        "    for i in range(len(data_tokens)):\n",
        "      for j in range(len(data_tokens[i])):\n",
        "        if seq_length + j > len(data_tokens[i]):\n",
        "          break\n",
        "        else:\n",
        "          #print(data_tokens_test_case[i][j:seq_length_test_case+j])\n",
        "          sequences.append(data_tokens[i][j:seq_length+j])\n",
        "    #End of the Code\n",
        "    return sequences"
      ],
      "id": "22e9d2da"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7399b900",
        "outputId": "a6529eb5-78d9-4003-a188-8c34e29cb8a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['this', 'is', 'a'], ['is', 'a', 'test'], ['a', 'test', 'case'], ['lets', 'try', 'another'], ['try', 'another', 'one']]\n"
          ]
        }
      ],
      "source": [
        "## Test Case\n",
        "data_tokens_test_case = [[\"this\", \"is\", \"a\", \"test\", \"case\"], [\"lets\", \"try\", \"another\", \"one\"]]\n",
        "seq_length_test_case = 3\n",
        "sequences_test_case = split_tokens_into_sequences(data_tokens_test_case, seq_length_test_case)\n",
        "\n",
        "print(sequences_test_case)\n",
        "\n",
        "### TEST CASE: The output should be like this:\n",
        "\n",
        "## [['this', 'is', 'a'], ['is', 'a', 'test'], ['a', 'test', 'case'], ['lets', 'try', 'another'], ['try', 'another', 'one']]"
      ],
      "id": "7399b900"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5d232316"
      },
      "outputs": [],
      "source": [
        "# define the sequence length for train and test\n",
        "seq_length = 10\n",
        "sequences_train = split_tokens_into_sequences(df_train['tokens'],seq_length)\n",
        "sequences_test  = split_tokens_into_sequences(df_test['tokens'],seq_length)"
      ],
      "id": "5d232316"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyaylGAG7odl",
        "outputId": "8085bb9e-c8a3-4f2b-a105-b8f95a4d79fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['who', 'were', 'they', 'kidding', 'with', 'this', 'there', 'was', 'just', 'too'], ['were', 'they', 'kidding', 'with', 'this', 'there', 'was', 'just', 'too', 'much'], ['they', 'kidding', 'with', 'this', 'there', 'was', 'just', 'too', 'much', 'in'], ['kidding', 'with', 'this', 'there', 'was', 'just', 'too', 'much', 'in', 'this'], ['with', 'this', 'there', 'was', 'just', 'too', 'much', 'in', 'this', 'film'], ['this', 'there', 'was', 'just', 'too', 'much', 'in', 'this', 'film', 'that'], ['there', 'was', 'just', 'too', 'much', 'in', 'this', 'film', 'that', 'was'], ['was', 'just', 'too', 'much', 'in', 'this', 'film', 'that', 'was', 'hard'], ['just', 'too', 'much', 'in', 'this', 'film', 'that', 'was', 'hard', 'to'], ['too', 'much', 'in', 'this', 'film', 'that', 'was', 'hard', 'to', 'digest'], ['much', 'in', 'this', 'film', 'that', 'was', 'hard', 'to', 'digest', 'right'], ['in', 'this', 'film', 'that', 'was', 'hard', 'to', 'digest', 'right', 'from'], ['this', 'film', 'that', 'was', 'hard', 'to', 'digest', 'right', 'from', 'when'], ['film', 'that', 'was', 'hard', 'to', 'digest', 'right', 'from', 'when', 'arjun'], ['that', 'was', 'hard', 'to', 'digest', 'right', 'from', 'when', 'arjun', 'ajay'], ['was', 'hard', 'to', 'digest', 'right', 'from', 'when', 'arjun', 'ajay', 'devgan'], ['hard', 'to', 'digest', 'right', 'from', 'when', 'arjun', 'ajay', 'devgan', 'unknowingly'], ['to', 'digest', 'right', 'from', 'when', 'arjun', 'ajay', 'devgan', 'unknowingly', 'wishes'], ['digest', 'right', 'from', 'when', 'arjun', 'ajay', 'devgan', 'unknowingly', 'wishes', 'death'], ['right', 'from', 'when', 'arjun', 'ajay', 'devgan', 'unknowingly', 'wishes', 'death', 'on'], ['from', 'when', 'arjun', 'ajay', 'devgan', 'unknowingly', 'wishes', 'death', 'on', 'his'], ['when', 'arjun', 'ajay', 'devgan', 'unknowingly', 'wishes', 'death', 'on', 'his', 'father'], ['arjun', 'ajay', 'devgan', 'unknowingly', 'wishes', 'death', 'on', 'his', 'father', 'to'], ['ajay', 'devgan', 'unknowingly', 'wishes', 'death', 'on', 'his', 'father', 'to', 'when'], ['devgan', 'unknowingly', 'wishes', 'death', 'on', 'his', 'father', 'to', 'when', 'he'], ['unknowingly', 'wishes', 'death', 'on', 'his', 'father', 'to', 'when', 'he', 'arrives'], ['wishes', 'death', 'on', 'his', 'father', 'to', 'when', 'he', 'arrives', 'in'], ['death', 'on', 'his', 'father', 'to', 'when', 'he', 'arrives', 'in', 'london'], ['on', 'his', 'father', 'to', 'when', 'he', 'arrives', 'in', 'london', 'with'], ['his', 'father', 'to', 'when', 'he', 'arrives', 'in', 'london', 'with', 'his'], ['father', 'to', 'when', 'he', 'arrives', 'in', 'london', 'with', 'his', 'uncleplayed'], ['to', 'when', 'he', 'arrives', 'in', 'london', 'with', 'his', 'uncleplayed', 'by'], ['when', 'he', 'arrives', 'in', 'london', 'with', 'his', 'uncleplayed', 'by', 'om'], ['he', 'arrives', 'in', 'london', 'with', 'his', 'uncleplayed', 'by', 'om', 'puri'], ['arrives', 'in', 'london', 'with', 'his', 'uncleplayed', 'by', 'om', 'puri', 'only'], ['in', 'london', 'with', 'his', 'uncleplayed', 'by', 'om', 'puri', 'only', 'to'], ['london', 'with', 'his', 'uncleplayed', 'by', 'om', 'puri', 'only', 'to', 'abandon'], ['with', 'his', 'uncleplayed', 'by', 'om', 'puri', 'only', 'to', 'abandon', 'him'], ['his', 'uncleplayed', 'by', 'om', 'puri', 'only', 'to', 'abandon', 'him', 'minutes'], ['uncleplayed', 'by', 'om', 'puri', 'only', 'to', 'abandon', 'him', 'minutes', 'later'], ['by', 'om', 'puri', 'only', 'to', 'abandon', 'him', 'minutes', 'later', 'the'], ['om', 'puri', 'only', 'to', 'abandon', 'him', 'minutes', 'later', 'the', 'only'], ['puri', 'only', 'to', 'abandon', 'him', 'minutes', 'later', 'the', 'only', 'problem'], ['only', 'to', 'abandon', 'him', 'minutes', 'later', 'the', 'only', 'problem', 'with'], ['to', 'abandon', 'him', 'minutes', 'later', 'the', 'only', 'problem', 'with', 'that'], ['abandon', 'him', 'minutes', 'later', 'the', 'only', 'problem', 'with', 'that', 'theory'], ['him', 'minutes', 'later', 'the', 'only', 'problem', 'with', 'that', 'theory', 'is'], ['minutes', 'later', 'the', 'only', 'problem', 'with', 'that', 'theory', 'is', 'that'], ['later', 'the', 'only', 'problem', 'with', 'that', 'theory', 'is', 'that', 'anybody'], ['the', 'only', 'problem', 'with', 'that', 'theory', 'is', 'that', 'anybody', 'who'], ['only', 'problem', 'with', 'that', 'theory', 'is', 'that', 'anybody', 'who', 'has'], ['problem', 'with', 'that', 'theory', 'is', 'that', 'anybody', 'who', 'has', 'ever'], ['with', 'that', 'theory', 'is', 'that', 'anybody', 'who', 'has', 'ever', 'passed'], ['that', 'theory', 'is', 'that', 'anybody', 'who', 'has', 'ever', 'passed', 'through'], ['theory', 'is', 'that', 'anybody', 'who', 'has', 'ever', 'passed', 'through', 'london'], ['is', 'that', 'anybody', 'who', 'has', 'ever', 'passed', 'through', 'london', 'heathrow'], ['that', 'anybody', 'who', 'has', 'ever', 'passed', 'through', 'london', 'heathrow', 'knows'], ['anybody', 'who', 'has', 'ever', 'passed', 'through', 'london', 'heathrow', 'knows', 'that'], ['who', 'has', 'ever', 'passed', 'through', 'london', 'heathrow', 'knows', 'that', 'such'], ['has', 'ever', 'passed', 'through', 'london', 'heathrow', 'knows', 'that', 'such', 'a'], ['ever', 'passed', 'through', 'london', 'heathrow', 'knows', 'that', 'such', 'a', 'fête'], ['passed', 'through', 'london', 'heathrow', 'knows', 'that', 'such', 'a', 'fête', 'would'], ['through', 'london', 'heathrow', 'knows', 'that', 'such', 'a', 'fête', 'would', 'be'], ['london', 'heathrow', 'knows', 'that', 'such', 'a', 'fête', 'would', 'be', 'impossible'], ['heathrow', 'knows', 'that', 'such', 'a', 'fête', 'would', 'be', 'impossible', 'to'], ['knows', 'that', 'such', 'a', 'fête', 'would', 'be', 'impossible', 'to', 'pull'], ['that', 'such', 'a', 'fête', 'would', 'be', 'impossible', 'to', 'pull', 'off'], ['such', 'a', 'fête', 'would', 'be', 'impossible', 'to', 'pull', 'off', 'and'], ['a', 'fête', 'would', 'be', 'impossible', 'to', 'pull', 'off', 'and', 'especially'], ['fête', 'would', 'be', 'impossible', 'to', 'pull', 'off', 'and', 'especially', 'not'], ['would', 'be', 'impossible', 'to', 'pull', 'off', 'and', 'especially', 'not', 'by'], ['be', 'impossible', 'to', 'pull', 'off', 'and', 'especially', 'not', 'by', 'an'], ['impossible', 'to', 'pull', 'off', 'and', 'especially', 'not', 'by', 'an', 'indian'], ['to', 'pull', 'off', 'and', 'especially', 'not', 'by', 'an', 'indian', 'but'], ['pull', 'off', 'and', 'especially', 'not', 'by', 'an', 'indian', 'but', 'the'], ['off', 'and', 'especially', 'not', 'by', 'an', 'indian', 'but', 'the', 'film'], ['and', 'especially', 'not', 'by', 'an', 'indian', 'but', 'the', 'film', 'problems'], ['especially', 'not', 'by', 'an', 'indian', 'but', 'the', 'film', 'problems', 'do'], ['not', 'by', 'an', 'indian', 'but', 'the', 'film', 'problems', 'do', 'not'], ['by', 'an', 'indian', 'but', 'the', 'film', 'problems', 'do', 'not', 'end'], ['an', 'indian', 'but', 'the', 'film', 'problems', 'do', 'not', 'end', 'there'], ['indian', 'but', 'the', 'film', 'problems', 'do', 'not', 'end', 'there', 'theres'], ['but', 'the', 'film', 'problems', 'do', 'not', 'end', 'there', 'theres', 'the'], ['the', 'film', 'problems', 'do', 'not', 'end', 'there', 'theres', 'the', 'issue'], ['film', 'problems', 'do', 'not', 'end', 'there', 'theres', 'the', 'issue', 'of'], ['problems', 'do', 'not', 'end', 'there', 'theres', 'the', 'issue', 'of', 'the'], ['do', 'not', 'end', 'there', 'theres', 'the', 'issue', 'of', 'the', 'two'], ['not', 'end', 'there', 'theres', 'the', 'issue', 'of', 'the', 'two', 'main'], ['end', 'there', 'theres', 'the', 'issue', 'of', 'the', 'two', 'main', 'leads'], ['there', 'theres', 'the', 'issue', 'of', 'the', 'two', 'main', 'leads', 'salman'], ['theres', 'the', 'issue', 'of', 'the', 'two', 'main', 'leads', 'salman', 'khan'], ['the', 'issue', 'of', 'the', 'two', 'main', 'leads', 'salman', 'khan', 'and'], ['issue', 'of', 'the', 'two', 'main', 'leads', 'salman', 'khan', 'and', 'ajay'], ['of', 'the', 'two', 'main', 'leads', 'salman', 'khan', 'and', 'ajay', 'devgan'], ['the', 'two', 'main', 'leads', 'salman', 'khan', 'and', 'ajay', 'devgan', 'passing'], ['two', 'main', 'leads', 'salman', 'khan', 'and', 'ajay', 'devgan', 'passing', 'as'], ['main', 'leads', 'salman', 'khan', 'and', 'ajay', 'devgan', 'passing', 'as', 'rockstars'], ['leads', 'salman', 'khan', 'and', 'ajay', 'devgan', 'passing', 'as', 'rockstars', 'on'], ['salman', 'khan', 'and', 'ajay', 'devgan', 'passing', 'as', 'rockstars', 'on', 'the'], ['khan', 'and', 'ajay', 'devgan', 'passing', 'as', 'rockstars', 'on', 'the', 'verge'], ['and', 'ajay', 'devgan', 'passing', 'as', 'rockstars', 'on', 'the', 'verge', 'of'], ['ajay', 'devgan', 'passing', 'as', 'rockstars', 'on', 'the', 'verge', 'of', 'achieving'], ['devgan', 'passing', 'as', 'rockstars', 'on', 'the', 'verge', 'of', 'achieving', 'their'], ['passing', 'as', 'rockstars', 'on', 'the', 'verge', 'of', 'achieving', 'their', 'dreams'], ['as', 'rockstars', 'on', 'the', 'verge', 'of', 'achieving', 'their', 'dreams', 'i'], ['rockstars', 'on', 'the', 'verge', 'of', 'achieving', 'their', 'dreams', 'i', 'mean'], ['on', 'the', 'verge', 'of', 'achieving', 'their', 'dreams', 'i', 'mean', 'yeah'], ['the', 'verge', 'of', 'achieving', 'their', 'dreams', 'i', 'mean', 'yeah', 'we'], ['verge', 'of', 'achieving', 'their', 'dreams', 'i', 'mean', 'yeah', 'we', 'saw'], ['of', 'achieving', 'their', 'dreams', 'i', 'mean', 'yeah', 'we', 'saw', 'success'], ['achieving', 'their', 'dreams', 'i', 'mean', 'yeah', 'we', 'saw', 'success', 'come'], ['their', 'dreams', 'i', 'mean', 'yeah', 'we', 'saw', 'success', 'come', 'to'], ['dreams', 'i', 'mean', 'yeah', 'we', 'saw', 'success', 'come', 'to', 'susan'], ['i', 'mean', 'yeah', 'we', 'saw', 'success', 'come', 'to', 'susan', 'boyle'], ['mean', 'yeah', 'we', 'saw', 'success', 'come', 'to', 'susan', 'boyle', 'a'], ['yeah', 'we', 'saw', 'success', 'come', 'to', 'susan', 'boyle', 'a', 'woman'], ['we', 'saw', 'success', 'come', 'to', 'susan', 'boyle', 'a', 'woman', 'in'], ['saw', 'success', 'come', 'to', 'susan', 'boyle', 'a', 'woman', 'in', 'the'], ['success', 'come', 'to', 'susan', 'boyle', 'a', 'woman', 'in', 'the', 'uk'], ['come', 'to', 'susan', 'boyle', 'a', 'woman', 'in', 'the', 'uk', 'achieving'], ['to', 'susan', 'boyle', 'a', 'woman', 'in', 'the', 'uk', 'achieving', 'her'], ['susan', 'boyle', 'a', 'woman', 'in', 'the', 'uk', 'achieving', 'her', 'dreams'], ['boyle', 'a', 'woman', 'in', 'the', 'uk', 'achieving', 'her', 'dreams', 'after'], ['a', 'woman', 'in', 'the', 'uk', 'achieving', 'her', 'dreams', 'after', 'age'], ['woman', 'in', 'the', 'uk', 'achieving', 'her', 'dreams', 'after', 'age', '50'], ['in', 'the', 'uk', 'achieving', 'her', 'dreams', 'after', 'age', '50', 'but'], ['the', 'uk', 'achieving', 'her', 'dreams', 'after', 'age', '50', 'but', 'that'], ['uk', 'achieving', 'her', 'dreams', 'after', 'age', '50', 'but', 'that', 'was'], ['achieving', 'her', 'dreams', 'after', 'age', '50', 'but', 'that', 'was', 'a'], ['her', 'dreams', 'after', 'age', '50', 'but', 'that', 'was', 'a', 'rare'], ['dreams', 'after', 'age', '50', 'but', 'that', 'was', 'a', 'rare', 'case'], ['after', 'age', '50', 'but', 'that', 'was', 'a', 'rare', 'case', 'it'], ['age', '50', 'but', 'that', 'was', 'a', 'rare', 'case', 'it', 'was'], ['50', 'but', 'that', 'was', 'a', 'rare', 'case', 'it', 'was', 'really'], ['but', 'that', 'was', 'a', 'rare', 'case', 'it', 'was', 'really', 'hard'], ['that', 'was', 'a', 'rare', 'case', 'it', 'was', 'really', 'hard', 'for'], ['was', 'a', 'rare', 'case', 'it', 'was', 'really', 'hard', 'for', 'me'], ['a', 'rare', 'case', 'it', 'was', 'really', 'hard', 'for', 'me', 'to'], ['rare', 'case', 'it', 'was', 'really', 'hard', 'for', 'me', 'to', 'suspend'], ['case', 'it', 'was', 'really', 'hard', 'for', 'me', 'to', 'suspend', 'my'], ['it', 'was', 'really', 'hard', 'for', 'me', 'to', 'suspend', 'my', 'disbelief'], ['was', 'really', 'hard', 'for', 'me', 'to', 'suspend', 'my', 'disbelief', 'because'], ['really', 'hard', 'for', 'me', 'to', 'suspend', 'my', 'disbelief', 'because', 'i'], ['hard', 'for', 'me', 'to', 'suspend', 'my', 'disbelief', 'because', 'i', 'felt'], ['for', 'me', 'to', 'suspend', 'my', 'disbelief', 'because', 'i', 'felt', 'that'], ['me', 'to', 'suspend', 'my', 'disbelief', 'because', 'i', 'felt', 'that', 'the'], ['to', 'suspend', 'my', 'disbelief', 'because', 'i', 'felt', 'that', 'the', 'casting'], ['suspend', 'my', 'disbelief', 'because', 'i', 'felt', 'that', 'the', 'casting', 'of'], ['my', 'disbelief', 'because', 'i', 'felt', 'that', 'the', 'casting', 'of', 'salman'], ['disbelief', 'because', 'i', 'felt', 'that', 'the', 'casting', 'of', 'salman', 'and'], ['because', 'i', 'felt', 'that', 'the', 'casting', 'of', 'salman', 'and', 'ajay'], ['i', 'felt', 'that', 'the', 'casting', 'of', 'salman', 'and', 'ajay', 'was'], ['felt', 'that', 'the', 'casting', 'of', 'salman', 'and', 'ajay', 'was', 'just'], ['that', 'the', 'casting', 'of', 'salman', 'and', 'ajay', 'was', 'just', 'illconceived'], ['the', 'casting', 'of', 'salman', 'and', 'ajay', 'was', 'just', 'illconceived', 'they'], ['casting', 'of', 'salman', 'and', 'ajay', 'was', 'just', 'illconceived', 'they', 'would'], ['of', 'salman', 'and', 'ajay', 'was', 'just', 'illconceived', 'they', 'would', 'never'], ['salman', 'and', 'ajay', 'was', 'just', 'illconceived', 'they', 'would', 'never', 'cast'], ['and', 'ajay', 'was', 'just', 'illconceived', 'they', 'would', 'never', 'cast', 'madhuri'], ['ajay', 'was', 'just', 'illconceived', 'they', 'would', 'never', 'cast', 'madhuri', 'dixit'], ['was', 'just', 'illconceived', 'they', 'would', 'never', 'cast', 'madhuri', 'dixit', 'and'], ['just', 'illconceived', 'they', 'would', 'never', 'cast', 'madhuri', 'dixit', 'and', 'sridevi'], ['illconceived', 'they', 'would', 'never', 'cast', 'madhuri', 'dixit', 'and', 'sridevi', 'to'], ['they', 'would', 'never', 'cast', 'madhuri', 'dixit', 'and', 'sridevi', 'to', 'play'], ['would', 'never', 'cast', 'madhuri', 'dixit', 'and', 'sridevi', 'to', 'play', 'the'], ['never', 'cast', 'madhuri', 'dixit', 'and', 'sridevi', 'to', 'play', 'the', 'same'], ['cast', 'madhuri', 'dixit', 'and', 'sridevi', 'to', 'play', 'the', 'same', 'roles'], ['madhuri', 'dixit', 'and', 'sridevi', 'to', 'play', 'the', 'same', 'roles', 'so'], ['dixit', 'and', 'sridevi', 'to', 'play', 'the', 'same', 'roles', 'so', 'why'], ['and', 'sridevi', 'to', 'play', 'the', 'same', 'roles', 'so', 'why', 'should'], ['sridevi', 'to', 'play', 'the', 'same', 'roles', 'so', 'why', 'should', 'we'], ['to', 'play', 'the', 'same', 'roles', 'so', 'why', 'should', 'we', 'be'], ['play', 'the', 'same', 'roles', 'so', 'why', 'should', 'we', 'be', 'forced'], ['the', 'same', 'roles', 'so', 'why', 'should', 'we', 'be', 'forced', 'to'], ['same', 'roles', 'so', 'why', 'should', 'we', 'be', 'forced', 'to', 'watch'], ['roles', 'so', 'why', 'should', 'we', 'be', 'forced', 'to', 'watch', 'ajay'], ['so', 'why', 'should', 'we', 'be', 'forced', 'to', 'watch', 'ajay', 'devgan'], ['why', 'should', 'we', 'be', 'forced', 'to', 'watch', 'ajay', 'devgan', 'and'], ['should', 'we', 'be', 'forced', 'to', 'watch', 'ajay', 'devgan', 'and', 'salman'], ['we', 'be', 'forced', 'to', 'watch', 'ajay', 'devgan', 'and', 'salman', 'khan'], ['be', 'forced', 'to', 'watch', 'ajay', 'devgan', 'and', 'salman', 'khan', 'men'], ['forced', 'to', 'watch', 'ajay', 'devgan', 'and', 'salman', 'khan', 'men', 'well'], ['to', 'watch', 'ajay', 'devgan', 'and', 'salman', 'khan', 'men', 'well', 'into'], ['watch', 'ajay', 'devgan', 'and', 'salman', 'khan', 'men', 'well', 'into', 'their'], ['ajay', 'devgan', 'and', 'salman', 'khan', 'men', 'well', 'into', 'their', '40s'], ['devgan', 'and', 'salman', 'khan', 'men', 'well', 'into', 'their', '40s', 'prance'], ['and', 'salman', 'khan', 'men', 'well', 'into', 'their', '40s', 'prance', 'around'], ['salman', 'khan', 'men', 'well', 'into', 'their', '40s', 'prance', 'around', 'desperately'], ['khan', 'men', 'well', 'into', 'their', '40s', 'prance', 'around', 'desperately', 'trying'], ['men', 'well', 'into', 'their', '40s', 'prance', 'around', 'desperately', 'trying', 'to'], ['well', 'into', 'their', '40s', 'prance', 'around', 'desperately', 'trying', 'to', 'hang'], ['into', 'their', '40s', 'prance', 'around', 'desperately', 'trying', 'to', 'hang', 'on'], ['their', '40s', 'prance', 'around', 'desperately', 'trying', 'to', 'hang', 'on', 'to'], ['40s', 'prance', 'around', 'desperately', 'trying', 'to', 'hang', 'on', 'to', 'their'], ['prance', 'around', 'desperately', 'trying', 'to', 'hang', 'on', 'to', 'their', '20s'], ['around', 'desperately', 'trying', 'to', 'hang', 'on', 'to', 'their', '20s', 'lets'], ['desperately', 'trying', 'to', 'hang', 'on', 'to', 'their', '20s', 'lets', 'not'], ['trying', 'to', 'hang', 'on', 'to', 'their', '20s', 'lets', 'not', 'even'], ['to', 'hang', 'on', 'to', 'their', '20s', 'lets', 'not', 'even', 'talk'], ['hang', 'on', 'to', 'their', '20s', 'lets', 'not', 'even', 'talk', 'about'], ['on', 'to', 'their', '20s', 'lets', 'not', 'even', 'talk', 'about', 'the'], ['to', 'their', '20s', 'lets', 'not', 'even', 'talk', 'about', 'the', 'most'], ['their', '20s', 'lets', 'not', 'even', 'talk', 'about', 'the', 'most', 'selfconscious'], ['20s', 'lets', 'not', 'even', 'talk', 'about', 'the', 'most', 'selfconscious', 'actress'], ['lets', 'not', 'even', 'talk', 'about', 'the', 'most', 'selfconscious', 'actress', 'on'], ['not', 'even', 'talk', 'about', 'the', 'most', 'selfconscious', 'actress', 'on', 'screen'], ['even', 'talk', 'about', 'the', 'most', 'selfconscious', 'actress', 'on', 'screen', 'today'], ['talk', 'about', 'the', 'most', 'selfconscious', 'actress', 'on', 'screen', 'today', 'asin'], ['about', 'the', 'most', 'selfconscious', 'actress', 'on', 'screen', 'today', 'asin', 'this'], ['the', 'most', 'selfconscious', 'actress', 'on', 'screen', 'today', 'asin', 'this', 'is'], ['most', 'selfconscious', 'actress', 'on', 'screen', 'today', 'asin', 'this', 'is', 'her'], ['selfconscious', 'actress', 'on', 'screen', 'today', 'asin', 'this', 'is', 'her', 'second'], ['actress', 'on', 'screen', 'today', 'asin', 'this', 'is', 'her', 'second', 'film'], ['on', 'screen', 'today', 'asin', 'this', 'is', 'her', 'second', 'film', 'that'], ['screen', 'today', 'asin', 'this', 'is', 'her', 'second', 'film', 'that', 'i'], ['today', 'asin', 'this', 'is', 'her', 'second', 'film', 'that', 'i', 'have'], ['asin', 'this', 'is', 'her', 'second', 'film', 'that', 'i', 'have', 'seen'], ['this', 'is', 'her', 'second', 'film', 'that', 'i', 'have', 'seen', 'and'], ['is', 'her', 'second', 'film', 'that', 'i', 'have', 'seen', 'and', 'she'], ['her', 'second', 'film', 'that', 'i', 'have', 'seen', 'and', 'she', 'is'], ['second', 'film', 'that', 'i', 'have', 'seen', 'and', 'she', 'is', 'just'], ['film', 'that', 'i', 'have', 'seen', 'and', 'she', 'is', 'just', 'hopeless'], ['that', 'i', 'have', 'seen', 'and', 'she', 'is', 'just', 'hopeless', 'as'], ['i', 'have', 'seen', 'and', 'she', 'is', 'just', 'hopeless', 'as', 'an'], ['have', 'seen', 'and', 'she', 'is', 'just', 'hopeless', 'as', 'an', 'actress'], ['seen', 'and', 'she', 'is', 'just', 'hopeless', 'as', 'an', 'actress', 'so'], ['and', 'she', 'is', 'just', 'hopeless', 'as', 'an', 'actress', 'so', 'conscious'], ['she', 'is', 'just', 'hopeless', 'as', 'an', 'actress', 'so', 'conscious', 'of'], ['is', 'just', 'hopeless', 'as', 'an', 'actress', 'so', 'conscious', 'of', 'her'], ['just', 'hopeless', 'as', 'an', 'actress', 'so', 'conscious', 'of', 'her', 'looks'], ['hopeless', 'as', 'an', 'actress', 'so', 'conscious', 'of', 'her', 'looks', 'that'], ['as', 'an', 'actress', 'so', 'conscious', 'of', 'her', 'looks', 'that', 'she'], ['an', 'actress', 'so', 'conscious', 'of', 'her', 'looks', 'that', 'she', 'only'], ['actress', 'so', 'conscious', 'of', 'her', 'looks', 'that', 'she', 'only', 'concerns'], ['so', 'conscious', 'of', 'her', 'looks', 'that', 'she', 'only', 'concerns', 'herself'], ['conscious', 'of', 'her', 'looks', 'that', 'she', 'only', 'concerns', 'herself', 'with'], ['of', 'her', 'looks', 'that', 'she', 'only', 'concerns', 'herself', 'with', 'looking'], ['her', 'looks', 'that', 'she', 'only', 'concerns', 'herself', 'with', 'looking', 'good'], ['looks', 'that', 'she', 'only', 'concerns', 'herself', 'with', 'looking', 'good', 'and'], ['that', 'she', 'only', 'concerns', 'herself', 'with', 'looking', 'good', 'and', 'voguing'], ['she', 'only', 'concerns', 'herself', 'with', 'looking', 'good', 'and', 'voguing', 'for'], ['only', 'concerns', 'herself', 'with', 'looking', 'good', 'and', 'voguing', 'for', 'the'], ['concerns', 'herself', 'with', 'looking', 'good', 'and', 'voguing', 'for', 'the', 'camera'], ['herself', 'with', 'looking', 'good', 'and', 'voguing', 'for', 'the', 'camera', 'rather'], ['with', 'looking', 'good', 'and', 'voguing', 'for', 'the', 'camera', 'rather', 'than'], ['looking', 'good', 'and', 'voguing', 'for', 'the', 'camera', 'rather', 'than', 'giving'], ['good', 'and', 'voguing', 'for', 'the', 'camera', 'rather', 'than', 'giving', 'in'], ['and', 'voguing', 'for', 'the', 'camera', 'rather', 'than', 'giving', 'in', 'a'], ['voguing', 'for', 'the', 'camera', 'rather', 'than', 'giving', 'in', 'a', 'good'], ['for', 'the', 'camera', 'rather', 'than', 'giving', 'in', 'a', 'good', 'acting'], ['the', 'camera', 'rather', 'than', 'giving', 'in', 'a', 'good', 'acting', 'performance'], ['camera', 'rather', 'than', 'giving', 'in', 'a', 'good', 'acting', 'performance', 'its'], ['rather', 'than', 'giving', 'in', 'a', 'good', 'acting', 'performance', 'its', 'just'], ['than', 'giving', 'in', 'a', 'good', 'acting', 'performance', 'its', 'just', 'hard'], ['giving', 'in', 'a', 'good', 'acting', 'performance', 'its', 'just', 'hard', 'to'], ['in', 'a', 'good', 'acting', 'performance', 'its', 'just', 'hard', 'to', 'believe'], ['a', 'good', 'acting', 'performance', 'its', 'just', 'hard', 'to', 'believe', 'that'], ['good', 'acting', 'performance', 'its', 'just', 'hard', 'to', 'believe', 'that', 'she'], ['acting', 'performance', 'its', 'just', 'hard', 'to', 'believe', 'that', 'she', 'turned'], ['performance', 'its', 'just', 'hard', 'to', 'believe', 'that', 'she', 'turned', 'down'], ['its', 'just', 'hard', 'to', 'believe', 'that', 'she', 'turned', 'down', 'all'], ['just', 'hard', 'to', 'believe', 'that', 'she', 'turned', 'down', 'all', 'those'], ['hard', 'to', 'believe', 'that', 'she', 'turned', 'down', 'all', 'those', 'other'], ['to', 'believe', 'that', 'she', 'turned', 'down', 'all', 'those', 'other', 'movie'], ['believe', 'that', 'she', 'turned', 'down', 'all', 'those', 'other', 'movie', 'roles'], ['that', 'she', 'turned', 'down', 'all', 'those', 'other', 'movie', 'roles', 'to'], ['she', 'turned', 'down', 'all', 'those', 'other', 'movie', 'roles', 'to', 'star'], ['turned', 'down', 'all', 'those', 'other', 'movie', 'roles', 'to', 'star', 'in'], ['down', 'all', 'those', 'other', 'movie', 'roles', 'to', 'star', 'in', 'this'], ['all', 'those', 'other', 'movie', 'roles', 'to', 'star', 'in', 'this', 'fluff'], ['those', 'other', 'movie', 'roles', 'to', 'star', 'in', 'this', 'fluff', 'and'], ['other', 'movie', 'roles', 'to', 'star', 'in', 'this', 'fluff', 'and', 'then'], ['movie', 'roles', 'to', 'star', 'in', 'this', 'fluff', 'and', 'then', 'be'], ['roles', 'to', 'star', 'in', 'this', 'fluff', 'and', 'then', 'be', 'so'], ['to', 'star', 'in', 'this', 'fluff', 'and', 'then', 'be', 'so', 'fluffy'], ['star', 'in', 'this', 'fluff', 'and', 'then', 'be', 'so', 'fluffy', 'as'], ['in', 'this', 'fluff', 'and', 'then', 'be', 'so', 'fluffy', 'as', 'an'], ['this', 'fluff', 'and', 'then', 'be', 'so', 'fluffy', 'as', 'an', 'actress'], ['fluff', 'and', 'then', 'be', 'so', 'fluffy', 'as', 'an', 'actress', 'nothing'], ['and', 'then', 'be', 'so', 'fluffy', 'as', 'an', 'actress', 'nothing', 'to'], ['then', 'be', 'so', 'fluffy', 'as', 'an', 'actress', 'nothing', 'to', 'write'], ['be', 'so', 'fluffy', 'as', 'an', 'actress', 'nothing', 'to', 'write', 'home'], ['so', 'fluffy', 'as', 'an', 'actress', 'nothing', 'to', 'write', 'home', 'about'], ['fluffy', 'as', 'an', 'actress', 'nothing', 'to', 'write', 'home', 'about', 'at'], ['as', 'an', 'actress', 'nothing', 'to', 'write', 'home', 'about', 'at', 'all'], ['an', 'actress', 'nothing', 'to', 'write', 'home', 'about', 'at', 'all', 'and'], ['actress', 'nothing', 'to', 'write', 'home', 'about', 'at', 'all', 'and', 'to'], ['nothing', 'to', 'write', 'home', 'about', 'at', 'all', 'and', 'to', 'top'], ['to', 'write', 'home', 'about', 'at', 'all', 'and', 'to', 'top', 'all'], ['write', 'home', 'about', 'at', 'all', 'and', 'to', 'top', 'all', 'of'], ['home', 'about', 'at', 'all', 'and', 'to', 'top', 'all', 'of', 'that'], ['about', 'at', 'all', 'and', 'to', 'top', 'all', 'of', 'that', 'the'], ['at', 'all', 'and', 'to', 'top', 'all', 'of', 'that', 'the', 'film'], ['all', 'and', 'to', 'top', 'all', 'of', 'that', 'the', 'film', 'just'], ['and', 'to', 'top', 'all', 'of', 'that', 'the', 'film', 'just', 'boringly'], ['to', 'top', 'all', 'of', 'that', 'the', 'film', 'just', 'boringly', 'dragged'], ['top', 'all', 'of', 'that', 'the', 'film', 'just', 'boringly', 'dragged', 'on'], ['all', 'of', 'that', 'the', 'film', 'just', 'boringly', 'dragged', 'on', 'theres'], ['of', 'that', 'the', 'film', 'just', 'boringly', 'dragged', 'on', 'theres', 'nothing'], ['that', 'the', 'film', 'just', 'boringly', 'dragged', 'on', 'theres', 'nothing', 'special'], ['the', 'film', 'just', 'boringly', 'dragged', 'on', 'theres', 'nothing', 'special', 'about'], ['film', 'just', 'boringly', 'dragged', 'on', 'theres', 'nothing', 'special', 'about', 'it'], ['just', 'boringly', 'dragged', 'on', 'theres', 'nothing', 'special', 'about', 'it', 'at'], ['boringly', 'dragged', 'on', 'theres', 'nothing', 'special', 'about', 'it', 'at', 'all'], ['dragged', 'on', 'theres', 'nothing', 'special', 'about', 'it', 'at', 'all', 'trust'], ['on', 'theres', 'nothing', 'special', 'about', 'it', 'at', 'all', 'trust', 'me'], ['theres', 'nothing', 'special', 'about', 'it', 'at', 'all', 'trust', 'me', 'you'], ['nothing', 'special', 'about', 'it', 'at', 'all', 'trust', 'me', 'you', 'will'], ['special', 'about', 'it', 'at', 'all', 'trust', 'me', 'you', 'will', 'predict'], ['about', 'it', 'at', 'all', 'trust', 'me', 'you', 'will', 'predict', 'every'], ['it', 'at', 'all', 'trust', 'me', 'you', 'will', 'predict', 'every', 'clichéd'], ['at', 'all', 'trust', 'me', 'you', 'will', 'predict', 'every', 'clichéd', 'thing'], ['all', 'trust', 'me', 'you', 'will', 'predict', 'every', 'clichéd', 'thing', 'that'], ['trust', 'me', 'you', 'will', 'predict', 'every', 'clichéd', 'thing', 'that', 'is'], ['me', 'you', 'will', 'predict', 'every', 'clichéd', 'thing', 'that', 'is', 'going'], ['you', 'will', 'predict', 'every', 'clichéd', 'thing', 'that', 'is', 'going', 'to'], ['will', 'predict', 'every', 'clichéd', 'thing', 'that', 'is', 'going', 'to', 'happen'], ['predict', 'every', 'clichéd', 'thing', 'that', 'is', 'going', 'to', 'happen', 'in'], ['every', 'clichéd', 'thing', 'that', 'is', 'going', 'to', 'happen', 'in', 'it'], ['i', 'instantly', 'fell', 'in', 'love', 'with', 'pushing', 'daisies', 'this', 'show'], ['instantly', 'fell', 'in', 'love', 'with', 'pushing', 'daisies', 'this', 'show', 'manages'], ['fell', 'in', 'love', 'with', 'pushing', 'daisies', 'this', 'show', 'manages', 'to'], ['in', 'love', 'with', 'pushing', 'daisies', 'this', 'show', 'manages', 'to', 'put'], ['love', 'with', 'pushing', 'daisies', 'this', 'show', 'manages', 'to', 'put', 'a'], ['with', 'pushing', 'daisies', 'this', 'show', 'manages', 'to', 'put', 'a', 'smile'], ['pushing', 'daisies', 'this', 'show', 'manages', 'to', 'put', 'a', 'smile', 'on'], ['daisies', 'this', 'show', 'manages', 'to', 'put', 'a', 'smile', 'on', 'my'], ['this', 'show', 'manages', 'to', 'put', 'a', 'smile', 'on', 'my', 'face'], ['show', 'manages', 'to', 'put', 'a', 'smile', 'on', 'my', 'face', 'with'], ['manages', 'to', 'put', 'a', 'smile', 'on', 'my', 'face', 'with', 'its'], ['to', 'put', 'a', 'smile', 'on', 'my', 'face', 'with', 'its', 'great'], ['put', 'a', 'smile', 'on', 'my', 'face', 'with', 'its', 'great', 'storytelling'], ['a', 'smile', 'on', 'my', 'face', 'with', 'its', 'great', 'storytelling', 'witty'], ['smile', 'on', 'my', 'face', 'with', 'its', 'great', 'storytelling', 'witty', 'dialog'], ['on', 'my', 'face', 'with', 'its', 'great', 'storytelling', 'witty', 'dialog', 'and'], ['my', 'face', 'with', 'its', 'great', 'storytelling', 'witty', 'dialog', 'and', 'great'], ['face', 'with', 'its', 'great', 'storytelling', 'witty', 'dialog', 'and', 'great', 'acting'], ['with', 'its', 'great', 'storytelling', 'witty', 'dialog', 'and', 'great', 'acting', 'but'], ['its', 'great', 'storytelling', 'witty', 'dialog', 'and', 'great', 'acting', 'but', 'thats'], ['great', 'storytelling', 'witty', 'dialog', 'and', 'great', 'acting', 'but', 'thats', 'not'], ['storytelling', 'witty', 'dialog', 'and', 'great', 'acting', 'but', 'thats', 'not', 'all'], ['witty', 'dialog', 'and', 'great', 'acting', 'but', 'thats', 'not', 'all', 'it'], ['dialog', 'and', 'great', 'acting', 'but', 'thats', 'not', 'all', 'it', 'also'], ['and', 'great', 'acting', 'but', 'thats', 'not', 'all', 'it', 'also', 'manages'], ['great', 'acting', 'but', 'thats', 'not', 'all', 'it', 'also', 'manages', 'to'], ['acting', 'but', 'thats', 'not', 'all', 'it', 'also', 'manages', 'to', 'keep'], ['but', 'thats', 'not', 'all', 'it', 'also', 'manages', 'to', 'keep', 'you'], ['thats', 'not', 'all', 'it', 'also', 'manages', 'to', 'keep', 'you', 'until'], ['not', 'all', 'it', 'also', 'manages', 'to', 'keep', 'you', 'until', 'the'], ['all', 'it', 'also', 'manages', 'to', 'keep', 'you', 'until', 'the', 'end'], ['it', 'also', 'manages', 'to', 'keep', 'you', 'until', 'the', 'end', 'the'], ['also', 'manages', 'to', 'keep', 'you', 'until', 'the', 'end', 'the', 'basic'], ['manages', 'to', 'keep', 'you', 'until', 'the', 'end', 'the', 'basic', 'idea'], ['to', 'keep', 'you', 'until', 'the', 'end', 'the', 'basic', 'idea', 'behind'], ['keep', 'you', 'until', 'the', 'end', 'the', 'basic', 'idea', 'behind', 'the'], ['you', 'until', 'the', 'end', 'the', 'basic', 'idea', 'behind', 'the', 'show'], ['until', 'the', 'end', 'the', 'basic', 'idea', 'behind', 'the', 'show', 'bringing'], ['the', 'end', 'the', 'basic', 'idea', 'behind', 'the', 'show', 'bringing', 'people'], ['end', 'the', 'basic', 'idea', 'behind', 'the', 'show', 'bringing', 'people', 'back'], ['the', 'basic', 'idea', 'behind', 'the', 'show', 'bringing', 'people', 'back', 'to'], ['basic', 'idea', 'behind', 'the', 'show', 'bringing', 'people', 'back', 'to', 'life'], ['idea', 'behind', 'the', 'show', 'bringing', 'people', 'back', 'to', 'life', 'with'], ['behind', 'the', 'show', 'bringing', 'people', 'back', 'to', 'life', 'with', 'one'], ['the', 'show', 'bringing', 'people', 'back', 'to', 'life', 'with', 'one', 'touch'], ['show', 'bringing', 'people', 'back', 'to', 'life', 'with', 'one', 'touch', 'ending'], ['bringing', 'people', 'back', 'to', 'life', 'with', 'one', 'touch', 'ending', 'the'], ['people', 'back', 'to', 'life', 'with', 'one', 'touch', 'ending', 'the', 'undead'], ['back', 'to', 'life', 'with', 'one', 'touch', 'ending', 'the', 'undead', 'status'], ['to', 'life', 'with', 'one', 'touch', 'ending', 'the', 'undead', 'status', 'with'], ['life', 'with', 'one', 'touch', 'ending', 'the', 'undead', 'status', 'with', 'a'], ['with', 'one', 'touch', 'ending', 'the', 'undead', 'status', 'with', 'a', 'second'], ['one', 'touch', 'ending', 'the', 'undead', 'status', 'with', 'a', 'second', 'is'], ['touch', 'ending', 'the', 'undead', 'status', 'with', 'a', 'second', 'is', 'interesting'], ['ending', 'the', 'undead', 'status', 'with', 'a', 'second', 'is', 'interesting', 'and'], ['the', 'undead', 'status', 'with', 'a', 'second', 'is', 'interesting', 'and', 'could'], ['undead', 'status', 'with', 'a', 'second', 'is', 'interesting', 'and', 'could', 'still'], ['status', 'with', 'a', 'second', 'is', 'interesting', 'and', 'could', 'still', 'be'], ['with', 'a', 'second', 'is', 'interesting', 'and', 'could', 'still', 'be', 'in'], ['a', 'second', 'is', 'interesting', 'and', 'could', 'still', 'be', 'in', 'later'], ['second', 'is', 'interesting', 'and', 'could', 'still', 'be', 'in', 'later', 'seasons'], ['is', 'interesting', 'and', 'could', 'still', 'be', 'in', 'later', 'seasons', 'but'], ['interesting', 'and', 'could', 'still', 'be', 'in', 'later', 'seasons', 'but', 'the'], ['and', 'could', 'still', 'be', 'in', 'later', 'seasons', 'but', 'the', 'suspenseful'], ['could', 'still', 'be', 'in', 'later', 'seasons', 'but', 'the', 'suspenseful', 'murder'], ['still', 'be', 'in', 'later', 'seasons', 'but', 'the', 'suspenseful', 'murder', 'cases'], ['be', 'in', 'later', 'seasons', 'but', 'the', 'suspenseful', 'murder', 'cases', 'the'], ['in', 'later', 'seasons', 'but', 'the', 'suspenseful', 'murder', 'cases', 'the', 'unique'], ['later', 'seasons', 'but', 'the', 'suspenseful', 'murder', 'cases', 'the', 'unique', 'look'], ['seasons', 'but', 'the', 'suspenseful', 'murder', 'cases', 'the', 'unique', 'look', 'of'], ['but', 'the', 'suspenseful', 'murder', 'cases', 'the', 'unique', 'look', 'of', 'the'], ['the', 'suspenseful', 'murder', 'cases', 'the', 'unique', 'look', 'of', 'the', 'show'], ['suspenseful', 'murder', 'cases', 'the', 'unique', 'look', 'of', 'the', 'show', 'and'], ['murder', 'cases', 'the', 'unique', 'look', 'of', 'the', 'show', 'and', 'the'], ['cases', 'the', 'unique', 'look', 'of', 'the', 'show', 'and', 'the', 'highly'], ['the', 'unique', 'look', 'of', 'the', 'show', 'and', 'the', 'highly', 'proficient'], ['unique', 'look', 'of', 'the', 'show', 'and', 'the', 'highly', 'proficient', 'narrator'], ['look', 'of', 'the', 'show', 'and', 'the', 'highly', 'proficient', 'narrator', 'add'], ['of', 'the', 'show', 'and', 'the', 'highly', 'proficient', 'narrator', 'add', 'to'], ['the', 'show', 'and', 'the', 'highly', 'proficient', 'narrator', 'add', 'to', 'the'], ['show', 'and', 'the', 'highly', 'proficient', 'narrator', 'add', 'to', 'the', 'experience'], ['and', 'the', 'highly', 'proficient', 'narrator', 'add', 'to', 'the', 'experience', 'but'], ['the', 'highly', 'proficient', 'narrator', 'add', 'to', 'the', 'experience', 'but', 'pushing'], ['highly', 'proficient', 'narrator', 'add', 'to', 'the', 'experience', 'but', 'pushing', 'daisies'], ['proficient', 'narrator', 'add', 'to', 'the', 'experience', 'but', 'pushing', 'daisies', 'is'], ['narrator', 'add', 'to', 'the', 'experience', 'but', 'pushing', 'daisies', 'is', 'more'], ['add', 'to', 'the', 'experience', 'but', 'pushing', 'daisies', 'is', 'more', 'than'], ['to', 'the', 'experience', 'but', 'pushing', 'daisies', 'is', 'more', 'than', 'its'], ['the', 'experience', 'but', 'pushing', 'daisies', 'is', 'more', 'than', 'its', 'parts'], ['experience', 'but', 'pushing', 'daisies', 'is', 'more', 'than', 'its', 'parts', 'it'], ['but', 'pushing', 'daisies', 'is', 'more', 'than', 'its', 'parts', 'it', 'has'], ['pushing', 'daisies', 'is', 'more', 'than', 'its', 'parts', 'it', 'has', 'a'], ['daisies', 'is', 'more', 'than', 'its', 'parts', 'it', 'has', 'a', 'certain'], ['is', 'more', 'than', 'its', 'parts', 'it', 'has', 'a', 'certain', 'charm'], ['more', 'than', 'its', 'parts', 'it', 'has', 'a', 'certain', 'charm', 'that'], ['than', 'its', 'parts', 'it', 'has', 'a', 'certain', 'charm', 'that', 'i'], ['its', 'parts', 'it', 'has', 'a', 'certain', 'charm', 'that', 'i', 'really'], ['parts', 'it', 'has', 'a', 'certain', 'charm', 'that', 'i', 'really', 'enjoy'], ['it', 'has', 'a', 'certain', 'charm', 'that', 'i', 'really', 'enjoy', 'and'], ['has', 'a', 'certain', 'charm', 'that', 'i', 'really', 'enjoy', 'and', 'im'], ['a', 'certain', 'charm', 'that', 'i', 'really', 'enjoy', 'and', 'im', 'looking'], ['certain', 'charm', 'that', 'i', 'really', 'enjoy', 'and', 'im', 'looking', 'forward'], ['charm', 'that', 'i', 'really', 'enjoy', 'and', 'im', 'looking', 'forward', 'to'], ['that', 'i', 'really', 'enjoy', 'and', 'im', 'looking', 'forward', 'to', 'enter'], ['i', 'really', 'enjoy', 'and', 'im', 'looking', 'forward', 'to', 'enter', 'the'], ['really', 'enjoy', 'and', 'im', 'looking', 'forward', 'to', 'enter', 'the', 'world'], ['enjoy', 'and', 'im', 'looking', 'forward', 'to', 'enter', 'the', 'world', 'of'], ['and', 'im', 'looking', 'forward', 'to', 'enter', 'the', 'world', 'of', 'ned'], ['im', 'looking', 'forward', 'to', 'enter', 'the', 'world', 'of', 'ned', 'and'], ['looking', 'forward', 'to', 'enter', 'the', 'world', 'of', 'ned', 'and', 'chuck'], ['forward', 'to', 'enter', 'the', 'world', 'of', 'ned', 'and', 'chuck', 'for'], ['to', 'enter', 'the', 'world', 'of', 'ned', 'and', 'chuck', 'for', 'a'], ['enter', 'the', 'world', 'of', 'ned', 'and', 'chuck', 'for', 'a', 'second'], ['the', 'world', 'of', 'ned', 'and', 'chuck', 'for', 'a', 'second', 'season']]\n"
          ]
        }
      ],
      "source": [
        "## Evaluation case: (Please provide the output of this function in your PDF answer)\n",
        "data_tokens_Evaluation_case = df_train['tokens'].tolist()[7:9] \n",
        "sequences_Evaluation_case = split_tokens_into_sequences(data_tokens_Evaluation_case, seq_length)\n",
        "\n",
        "print(sequences_Evaluation_case)"
      ],
      "id": "kyaylGAG7odl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b86c8e5"
      },
      "source": [
        "### Transform sequence to IDs \n",
        "\n",
        "The `preprocess_sequence_to_ids` function accepts an index, a list of sequences, and a dictionary that maps words to their corresponding IDs. Its purpose is to convert a sequence of text to a sequence of corresponding IDs using the provided word-to-ID dictionary. The input sequence is represented as a list of IDs, and the output sequence is represented as a single ID.\n",
        "\n",
        "Here's how the function works:\n",
        "\n",
        "1 - Iterate over each word in the input sequence, excluding the last word. For each word, check if it exists in the word2id dictionary. If it does, append its ID to the `input_sequence` list. If it doesn't, append the ID of the `<unk>` token to the `input_sequence` list.\n",
        "\n",
        "2 - Check if the last word in the sequence is in the word2id dictionary. If it is, set the `output_sequence` variable to the ID corresponding to that word. If it's not, set the `output_sequence` variable to the ID of the `<unk>` token.\n",
        "\n",
        "3 - Return the `input_sequence` and `output_sequence` variables as a tuple.\n",
        "\n",
        "Overall, this function preprocesses a given sequence of text by converting it to a sequence of corresponding IDs that can be used as input and output to a machine learning model. It also handles cases where a word in the sequence is not present in the provided word2id dictionary by setting its ID to the ID of the `<unk>` token.\n",
        "\n",
        "Example: \n",
        "if `index = 0`, `word2id = {'in': 0, 'this': 1, 'assignment': 2, 'you': 3, 'will': 4, 'learn': 5, 'about': 6, 'LSTM': 7, 'layer': 8, '<unk>': 9}` and `sequences = [['in', 'this', 'assignment', 'you', 'will'], ['this', 'assignment', 'you', 'will', 'learn'], ['assignment', 'you', 'will', 'learn', 'about'], ['you', 'will', 'learn', 'about', 'LSTM'], ['will', 'learn', 'about', 'LSTM','layer']]`\n",
        "    \n",
        "then the output of this function:  `input_sequence` = [0, 1, 2, 3] and `output_sequence` = 4   \n"
      ],
      "id": "9b86c8e5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ba1f861"
      },
      "source": [
        "#### Question 3  \n",
        "\n",
        "Write a function described above that takes in three arguments: an index, a list of sequences, and a word-to-ID dictionary, and returns a tuple containing the input sequence represented as a list of IDs and the output sequence represented as a single ID (Target ID)."
      ],
      "id": "8ba1f861"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0b4896d3"
      },
      "outputs": [],
      "source": [
        "def preprocess_sequence_to_ids(index, sequences, word2id):\n",
        "    \"\"\"\n",
        "    Convert a sequence of text to a sequence of corresponding IDs, using a provided word-to-ID dictionary.\n",
        "\n",
        "    Args:\n",
        "        index (int): The index of the sequence in the `sequences` list to preprocess.\n",
        "        sequences (list): A list of sequences, where each sequence is a list of words representing a text sample.\n",
        "        word2id (dict): A dictionary that maps words to their corresponding IDs.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the input sequence represented as a list of IDs, and the output sequence represented as a single ID.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize input_sequence and output_sequence\n",
        "    input_sequence = []\n",
        "    output_sequence = None\n",
        "    \n",
        "    # Student Code\n",
        "    b = len(sequences[index])-1\n",
        "    unk_tok_index = list(word2id.items()).index(('<unk>', word2id['<unk>']))\n",
        "\n",
        "    # a and b are index of last word, last word = sequences[a][b]\n",
        "    for j in range(len(sequences[index])-1):\n",
        "      if sequences[index][j] in word2id.keys():\n",
        "        key_to_find = sequences[index][j]\n",
        "        index_inoutseq = list(word2id.items()).index((key_to_find, word2id[key_to_find]))\n",
        "        input_sequence.append(index_inoutseq)\n",
        "      else:\n",
        "        input_sequence.append(unk_tok_index)\n",
        "\n",
        "    if sequences[index][b] in word2id.keys():\n",
        "      key_to_find = sequences[index][b]\n",
        "      index_outseq = list(word2id.items()).index((key_to_find, word2id[key_to_find]))\n",
        "      output_sequence = index_outseq\n",
        "    else:\n",
        "      output_sequence = unk_tok_index\n",
        " \n",
        "    # End of the code\n",
        "    \n",
        "    # Return the input_sequence and output_sequence as a tuple\n",
        "    return input_sequence, output_sequence"
      ],
      "id": "0b4896d3"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73a044ad",
        "outputId": "c31e26d2-f45b-4cd7-b6cd-541a223fd913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 4]\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "## Test Case.(Please provide the output of this function in your PDF answer)\n",
        "word2id_test_case = {'this': 0, 'is': 1, 'a': 2, 'test': 3, 'case': 4, 'lets': 5, 'try': 6, 'another': 7, 'one': 8, '<unk>': 9}\n",
        "sequences_test_case = [[\"this\", \"is\", \"a\"], [\"is\", \"a\", \"test\"], [\"a\", \"test\", \"case\"], [\"test\", \"case\", \".\"], [\"lets\", \"try\", \"another\"], [\"try\", \"another\", \"one\"], [\"another\", \"one\", \".\"]]\n",
        "input_sequence_test_case, output_sequence_test_case = preprocess_sequence_to_ids(3, sequences_test_case, word2id_test_case)\n",
        "\n",
        "print(input_sequence_test_case)\n",
        "print(output_sequence_test_case)\n",
        "\n",
        "\n",
        "### TEST CASE: The output should be like this:\n",
        "\n",
        "## [3, 4]\n",
        "## 9"
      ],
      "id": "73a044ad"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvozDErL8gQh",
        "outputId": "b15d1605-9dfa-4142-e02b-4ac5971c6896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[341, 342, 54, 343, 344, 345, 42, 31, 115]\n",
            "92\n"
          ]
        }
      ],
      "source": [
        "## Evaluation case: (Please provide the output of this function in your PDF answer)\n",
        "input_sequence_test_case, output_sequence_test_case = preprocess_sequence_to_ids(600, sequences_train, word2id)\n",
        "print(input_sequence_test_case)\n",
        "print(output_sequence_test_case)"
      ],
      "id": "hvozDErL8gQh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aee68ce0"
      },
      "source": [
        "## Data Loader: \n",
        "`DataLoader` is an essential component in PyTorch for loading and processing data in machine learning workflows. The purpose of the `DataLoader` is to provide an efficient and convenient way to feed data into machine learning models. It works by taking a dataset and returning a generator that iterates over the dataset, returning batches of samples that can be used for training or evaluation. The `DataLoader` takes care of batching, shuffling, and loading the data into memory, making it easy to work with large datasets. By using the `DataLoader`, machine learning practitioners can focus on designing and training their models, while leaving the data handling to PyTorch.\n",
        "\n",
        "### First, we create a class to handle our IMDB review dataset:\n",
        "The purpose of the class is to convert the words in each sequence to their corresponding IDs, and to handle unknown words by replacing them with a designated unknown token or ID. This is a common preprocessing step for NLP tasks, where text data needs to be represented as numerical values that can be processed by machine learning models.\n",
        "\n",
        "The `IMDBDataset` class is a subclass of PyTorch's `Dataset` class, which is used to create a dataset object that can be iterated over and sampled from. The `__len__` method of the class returns the number of sequences in the dataset, and the `__getitem__` method returns a single sequence at a given index in the dataset, with the input and output sequences represented as PyTorch `LongTensor` objects.\n",
        "\n",
        "The `__getitem__` method converts the words in each input sequence to their corresponding IDs using the `word2id` dictionary. If a word is not in the dictionary, it is replaced with the unknown token or ID. The method also returns the output sequence as a PyTorch `LongTensor` object, where the output sequence is simply the ID of the last word in the input sequence.\n",
        "\n",
        "Overall, the `IMDBDataset` class provides a convenient and efficient way to preprocess and load text data for NLP tasks in PyTorch. It handles the necessary preprocessing steps and returns the data in a format that can be easily fed into a PyTorch `DataLoader` for efficient training of NLP models."
      ],
      "id": "aee68ce0"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "37b17c1e"
      },
      "outputs": [],
      "source": [
        "class IMDBDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A PyTorch dataset for processing IMDB review data.\n",
        "\n",
        "    Args:\n",
        "        sequences (list): A list of sequences where each sequence is a list of words.\n",
        "        word2id (dict): A dictionary that maps words to their corresponding IDs.\n",
        "\n",
        "    Attributes:\n",
        "        sequences (list): A list of sequences where each sequence is a list of words.\n",
        "        word2id (dict): A dictionary that maps words to their corresponding IDs.\n",
        "\n",
        "    Methods:\n",
        "        __len__: Returns the length of the dataset.\n",
        "        __getitem__: Gets a sequence from the dataset at a given index and returns the input and output sequences as PyTorch LongTensors.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sequences, word2id):\n",
        "        \"\"\"\n",
        "        Initializes the IMDBDataset.\n",
        "\n",
        "        Args:\n",
        "            sequences (list): A list of sequences where each sequence is a list of words.\n",
        "            word2id (dict): A dictionary that maps words to their corresponding IDs.\n",
        "        \"\"\"\n",
        "        self.sequences = sequences\n",
        "        self.word2id = word2id\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the length of the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: The length of the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Gets a sequence from the dataset at a given index and returns the input and output sequences as PyTorch LongTensors.\n",
        "\n",
        "        Args:\n",
        "            index (int): The index of the sequence to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing the input and output sequences as PyTorch LongTensors.\n",
        "        \"\"\"\n",
        "        \n",
        "        input_sequence, output_sequence = preprocess_sequence_to_ids(index, self.sequences, self.word2id)\n",
        "        \n",
        "        return torch.LongTensor(input_sequence).to(device), torch.LongTensor([output_sequence]).to(device)"
      ],
      "id": "37b17c1e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29ff6ca1"
      },
      "source": [
        "## Efficient Data Handling in PyTorch with DataLoader and Custom Dataset Creation\n",
        "\n",
        "First, an instance of the `IMDBDataset` class is created, which takes in sequences and `word2id` as inputs. This dataset contains preprocessed sequences of text data from the IMDB dataset, where each sequence has been converted to a list of numerical IDs representing each word in the sequence.\n",
        "\n",
        "Next, a `DataLoader` instance is created using the `IMDBDataset` as input, along with two additional parameters. batch_size specifies the number of samples to include in each batch returned by the DataLoader, while shuffle specifies whether or not to shuffle the order of the samples in each batch.\n",
        "\n",
        "The resulting `dataloader` object can then be used to iterate over the dataset in batches, making it easy to feed the data into a PyTorch model for training or evaluation. This is a common technique used in machine learning to efficiently process large datasets in batches, rather than loading the entire dataset into memory at once."
      ],
      "id": "29ff6ca1"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "14cbe192"
      },
      "outputs": [],
      "source": [
        "# create a PyTorch dataset and dataloader\n",
        "dataset = IMDBDataset(sequences_train, word2id)\n",
        "dataloader = DataLoader(dataset, batch_size=512, shuffle=True)"
      ],
      "id": "14cbe192"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b1bb642"
      },
      "source": [
        "## Building an LSTM Unit from sctratch using Pytorch"
      ],
      "id": "0b1bb642"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86bd8716"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://i.imgur.com/ULyYais.png\" width=\"800\"/>\n",
        "</div>"
      ],
      "id": "86bd8716"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fee817d3"
      },
      "source": [
        "An LSTM unit takes as input a hidden state vector $\\mathbf{h}_{t-1}$ and an input vector $\\mathbf{x}_t$ at time $t$, and produces an output vector $\\mathbf{o}_t$ and an updated hidden state vector $\\mathbf{h}_t$. The computation can be broken down into several steps:"
      ],
      "id": "fee817d3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "450b847d"
      },
      "source": [
        "LSTM unit consist of four main gates: \n",
        "\n",
        "1 - Forget Gate: $f_t = \\sigma(W_{if}h_{t-1} + W_{hf}x_t + b_{if} + b_{hf})$\n",
        "\n",
        "2 - Input Gate: $ i_t = \\sigma(W_{ii}h_{t-1} + W_{hi}x_t + b_{ii} + b_{hi})$\n",
        "\n",
        "3 - Output Gate: $o_t = \\sigma(W_{io}h_{t-1}+ W_{ho}x_t + b_{io} + b_{ho})$\n",
        "\n",
        "4 - Memory Gate : $g_t = tanh(W_{im}h_{t-1}+W_{hm}x_t + b_{im} + b_{hm})$\n",
        "\n",
        "where: \n",
        "- $x_t$ represents the input at time step $t$.\n",
        "- $h_{t-1}$ represents the output of the RNN at the previous time step $t-1$.\n",
        "- $W_{i}$ represents the weight matrix that connects the input $x_t$ to the hidden state of the RNN.\n",
        "- $W_{h}$ represents the weight matrix that connects the previous hidden state $h_{t-1}$ to the current hidden - state.\n",
        "- $b_{i}$ and $b_{h}$ are the bias terms for the input and hidden state, respectively."
      ],
      "id": "450b847d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49dec47a"
      },
      "source": [
        "In a recurrent neural network (RNN), including LSTMs, the gates (including forget, input, and output gates) are typically calculated simultaneously because it allows the network to efficiently update the hidden state and selectively remember or forget information at each time step.\n",
        "\n",
        "Calculating all the gates at once involves matrix multiplication, which is a highly optimized operation in Pytorch library. By computing all the gates at once, the RNN can perform the calculations in parallel, which can result in faster training and inference times.\n",
        "\n",
        "Moreover, computing all the gates at once allows the RNN to selectively update its hidden state based on both the current input and the previous hidden state. This enables the RNN to selectively remember or forget information from the past while integrating new information from the current input.\n",
        "\n",
        "Overall, computing all the gates at once is an efficient and effective way to update the hidden state in a recurrent neural network.\n",
        "\n",
        "To do this we will create a weight matrix that combine $W_f$, $W_i$, $W_o$, and $W_m$ into one matrix:"
      ],
      "id": "49dec47a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbde269b"
      },
      "source": [
        "$$ W_{ih}= \\begin{bmatrix} W_if & W_ii & W_io & W_im \\end{bmatrix} $$\n",
        "$$ W_{hh}= \\begin{bmatrix} W_hf & W_hi & W_ho & W_hm \\end{bmatrix} $$\n",
        "\n",
        "Refer to the figure, it show how we will treat the matrix after concatenation:"
      ],
      "id": "dbde269b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10b447df"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://i.imgur.com/b95Aez3.png\" width=\"600\"/>\n",
        "</div>"
      ],
      "id": "10b447df"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba88cc37"
      },
      "source": [
        "\n",
        "same for bias's: \n",
        "\n",
        "$$ b_{ih}= \\begin{bmatrix} b_if & b_ii & b_io & b_im \\end{bmatrix} $$\n",
        "$$ b_{hh}= \\begin{bmatrix} b_hf & b_hi & b_ho & b_hm \\end{bmatrix} $$"
      ],
      "id": "ba88cc37"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1129a36f"
      },
      "source": [
        "So we calculate the for all gates as following:\n",
        "\n",
        "$$Gates = W_{ih}x_t +  W_{hh}h_{t-1} + b_{ih} + b_{hh}$$\n",
        "\n",
        "where $\\mathbf{x}$ is the input to the LSTM at time step $t$, $\\mathbf{W}{ih}$ and $\\mathbf{W}{hh}$ are the weight matrices for the input-to-hidden and hidden-to-hidden connections, respectively, $\\mathbf{h}{t-1}$ is the hidden state at the previous time step, and $\\mathbf{b}{ih}$ and $\\mathbf{b}_{hh}$ are the bias terms for the input-to-hidden and hidden-to-hidden connections, respectively. \n",
        "\n",
        "`Hint`: use \"@\" symbol in the code to do matrix multiplication operation."
      ],
      "id": "1129a36f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fccfd23"
      },
      "source": [
        "#### Question 4 \n",
        "\n",
        "Write a function that calculate the Gates for the LSTM different Gates."
      ],
      "id": "1fccfd23"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1b385b07"
      },
      "outputs": [],
      "source": [
        "def calculate_gates(x,W_ih,h_0,W_hh,b_ih,b_hh):\n",
        "    \"\"\"\n",
        "    Calculate the gates in an LSTM cell.\n",
        "\n",
        "    Args:\n",
        "    - x: Input tensor of shape (seq_len, batch_size, input_size)\n",
        "    - W_ih: Input-hidden weight tensor of shape (input_size, 4 * hidden_size)\n",
        "    - h_0: previous step hidden state tensor of shape (num_layers, batch_size, hidden_size)\n",
        "    - W_hh: Hidden-hidden weight tensor of shape (hidden_size, 4 * hidden_size)\n",
        "    - b_ih: Input-hidden bias tensor of shape (4 * hidden_size,)\n",
        "    - b_hh: Hidden-hidden bias tensor of shape (4 * hidden_size,)\n",
        "\n",
        "    Returns:\n",
        "    - gates: The gates tensor of shape (seq_len, batch_size, 4 * hidden_size)\n",
        "    \"\"\"\n",
        "    #Student Code\n",
        "    gates = None\n",
        "    seq_len = x.shape[0]\n",
        "    batch_size = x.shape[1]\n",
        "\n",
        "    input_size, four_hidden_size = W_ih.shape\n",
        "    hidden_size = int(four_hidden_size/4)\n",
        "    gates = torch.zeros(seq_len, batch_size, 4 * hidden_size)\n",
        "    #h_t = h_0\n",
        "\n",
        "\n",
        "    gates =  x @ W_ih  + h_0 @ W_hh  + b_ih + b_hh\n",
        "\n",
        "    return gates"
      ],
      "id": "1b385b07"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "973b6bc1",
        "outputId": "fac8a534-2f8b-4bd5-a806-a7df608429bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 83.,  94., 105., 116.,  99., 110., 121., 132.]],\n",
            "\n",
            "        [[164., 184., 204., 224., 216., 236., 256., 276.]]])\n"
          ]
        }
      ],
      "source": [
        "## Test Case (Please provide the output of this function in your PDF answer)\n",
        "x_test_case = torch.tensor([[[1, 2, 3]], [[4, 5, 6]]], dtype=torch.float32)\n",
        "W_ih_test_case = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16], [17, 18, 19, 20, 21, 22, 23, 24]], dtype=torch.float32) \n",
        "h_0_test_case = torch.tensor([[[1, 2]]], dtype=torch.float32) \n",
        "W_hh_test_case = torch.tensor([[1, 2, 3, 4,1,2,3,4], [5, 6, 7, 8,1,2,3,4]], dtype=torch.float32) \n",
        "b_ih_test_case = torch.tensor([[1, 2, 3, 4,1, 2, 3, 4]], dtype=torch.float32) \n",
        "b_hh_test_case = torch.tensor([[1, 2, 3, 4,1, 2, 3, 4]], dtype=torch.float32) \n",
        "\n",
        "# Test the function\n",
        "gates_test_case = calculate_gates(x_test_case, W_ih_test_case, h_0_test_case, W_hh_test_case, b_ih_test_case, b_hh_test_case)\n",
        "\n",
        "# Check that the output tensor has the expected shape and values\n",
        "print(gates_test_case)\n",
        "\n",
        "## TEST CASE: The output should be like this:\n",
        "## tensor([[[ 83.,  94., 105., 116.,  99., 110., 121., 132.]], [[164., 184., 204., 224., 216., 236., 256., 276.]]])"
      ],
      "id": "973b6bc1"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-FfBj5a9I1A",
        "outputId": "b1eda228-074e-4ba1-802e-4d9e80be7a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[142240.,  31791.,  58284.,  46173.,  64208.,  45249., 254676.,\n",
            "          181054.]],\n",
            "\n",
            "        [[146731.,  37801.,  40124.,  31342.,  54375.,  38983., 211406.,\n",
            "          183346.]]])\n"
          ]
        }
      ],
      "source": [
        "## Evaluation case: (Please provide the output of this function in your PDF answer)\n",
        "x_test_case = torch.tensor([[[45, 23, 54]], [[23, 46, 43]]], dtype=torch.float32)\n",
        "W_ih_test_case = torch.tensor([[23, 54, 867, 654, 34, 634, 756, 234], [234, 345, 56, 8, 34, 345, 15, 345], [35, 67, 34, 57, 897, 23, 2453, 45]], dtype=torch.float32) \n",
        "h_0_test_case = torch.tensor([[[23, 25]]], dtype=torch.float32) \n",
        "W_hh_test_case = torch.tensor([[5423, 234, 64, 46,45,245,3423,6453], [345, 345, 546, 456,456,23,324,434]], dtype=torch.float32) \n",
        "b_ih_test_case = torch.tensor([[234, 3456, 567, 567,345, 345, 786, 445]], dtype=torch.float32) \n",
        "b_hh_test_case = torch.tensor([[345, 345, 456, 456,678,987, 234, 445]], dtype=torch.float32) \n",
        "\n",
        "# Test the function\n",
        "gates_test_case = calculate_gates(x_test_case, W_ih_test_case, h_0_test_case, W_hh_test_case, b_ih_test_case, b_hh_test_case)\n",
        "\n",
        "# Check that the output tensor has the expected shape and values\n",
        "print(gates_test_case)"
      ],
      "id": "v-FfBj5a9I1A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fd318c2"
      },
      "source": [
        "`hint` = you can use `torch.sigmoid()` and `torch.tanh()`\n",
        "#### Question 5\n",
        "\n",
        "Write a function that split the gates into forget, input, memory, output gate? "
      ],
      "id": "5fd318c2"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6de6c8b9"
      },
      "outputs": [],
      "source": [
        "def calculate_each_gate(gates,hidden_size):\n",
        "    \"\"\"\n",
        "    Splits the input tensor `gates` into four gates: forget gate, input gate, memory gate, and output gate.\n",
        "\n",
        "    Args:\n",
        "    - gates: A tensor of shape (batch_size, 4 * hidden_size), containing the input to the LSTM layer.\n",
        "    - hidden_size: The number of units in the LSTM layer.\n",
        "\n",
        "    Returns:\n",
        "        Tuple of four tensors, each corresponding to a gate:\n",
        "            - forget gate: A tensor of shape (batch_size, hidden_size).\n",
        "            - input gate: A tensor of shape (batch_size, hidden_size).\n",
        "            - memory gate: A tensor of shape (batch_size, hidden_size).\n",
        "            - output gate: A tensor of shape (batch_size, hidden_size).\n",
        "    \"\"\"\n",
        "        \n",
        "    #Student Code\n",
        "    #gates_sig = torch.sigmoid(gates)\n",
        "    f_t_n, i_t_n, g_t_n, o_t_n = torch.split(gates, hidden_size, dim=1)\n",
        "\n",
        "    #Forget gate\n",
        "    f_t = torch.sigmoid(f_t_n)\n",
        "    \n",
        "    #Input gate\n",
        "    i_t = torch.sigmoid(i_t_n) \n",
        "    \n",
        "    # Memory gate\n",
        "    g_t = torch.tanh(g_t_n)\n",
        "    \n",
        "    # Output gate\n",
        "    o_t = torch.sigmoid(o_t_n)\n",
        "    \n",
        "    #End of the code\n",
        "    return f_t, i_t, g_t, o_t"
      ],
      "id": "6de6c8b9"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd9dd4c0",
        "outputId": "50949fe2-505f-4345-c193-94243fab357e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6225, 0.6457, 0.6682],\n",
            "        [0.7311, 0.7503, 0.7685]])\n",
            "tensor([[0.6900, 0.7109, 0.7311],\n",
            "        [0.7858, 0.8022, 0.8176]])\n",
            "tensor([[0.8005, 0.8337, 0.8005],\n",
            "        [0.9217, 0.9354, 0.8617]])\n",
            "tensor([[0.7685, 0.7503, 0.7685],\n",
            "        [0.8022, 0.8176, 0.8320]])\n"
          ]
        }
      ],
      "source": [
        "## Test Case (Please provide the output of this function in your PDF answer)\n",
        "\n",
        "gates_test_case = torch.tensor([[ 0.5,  0.6,  0.7,  0.8,  0.9,  1.0,  1.1,  1.2,  1.1,  1.2,  1.1,  1.2],\n",
        "                      [ 1.0,  1.1,  1.2,  1.3,  1.4,  1.5,  1.6,  1.7,  1.3,  1.4,  1.5,  1.6]], dtype=torch.float32) \n",
        "\n",
        "f_t_test_case , i_t_test_case , g_t_test_case , o_t_test_case   = calculate_each_gate(gates_test_case,3)\n",
        "print(f_t_test_case )\n",
        "print(i_t_test_case )\n",
        "print(g_t_test_case )\n",
        "print(o_t_test_case )\n",
        "\n",
        "## TEST CASE: The output should be like this:\n",
        "\n",
        "## tensor([[0.6225, 0.6457, 0.6682],\n",
        "##        [0.7311, 0.7503, 0.7685]])\n",
        "## tensor([[0.6900, 0.7109, 0.7311],\n",
        "##        [0.7858, 0.8022, 0.8176]])\n",
        "## tensor([[0.8005, 0.8337, 0.8005],\n",
        "##        [0.9217, 0.9354, 0.8617]])\n",
        "## tensor([[0.7685, 0.7503, 0.7685],\n",
        "##        [0.8022, 0.8176, 0.8320]])"
      ],
      "id": "fd9dd4c0"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoKfwFxD9SrA",
        "outputId": "9fff09f9-ab7b-4ae0-cdce-4cc92990013c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5842, 0.5572, 0.5572],\n",
            "        [0.9993, 0.9108, 1.0000]])\n",
            "tensor([[0.5307, 0.5572, 0.8429],\n",
            "        [0.9206, 0.9206, 1.0000]])\n",
            "tensor([[0.9508, 0.9979, 1.0000],\n",
            "        [1.0000, 1.0000, 0.9980]])\n",
            "tensor([[0.9621, 1.0000, 0.9206],\n",
            "        [0.9996, 0.9688, 0.9126]])\n"
          ]
        }
      ],
      "source": [
        "## Evaluation case: (Please provide the output of this function in your PDF answer)\n",
        "\n",
        "gates_test_case = torch.tensor([[ 0.34,  0.23,  0.23,  0.123,  0.23,  1.68,  1.84,  3.435,  9.345,  3.234,  23.45,  2.45],\n",
        "                                [ 7.234,  2.324,  32.4,  2.45,  2.45,  23.5,  7.58,  5.345,  3.456,  7.863,  3.4356,  2.3462]], dtype=torch.float32) \n",
        "\n",
        "f_t_test_case , i_t_test_case , g_t_test_case , o_t_test_case   = calculate_each_gate(gates_test_case,3)\n",
        "print(f_t_test_case )\n",
        "print(i_t_test_case )\n",
        "print(g_t_test_case )\n",
        "print(o_t_test_case )"
      ],
      "id": "DoKfwFxD9SrA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "587a7500"
      },
      "source": [
        "Update the cell state $\\mathbf{c}_t$:"
      ],
      "id": "587a7500"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14da0b22"
      },
      "source": [
        "$$ c_t = f_t \\odot c_0 + i_t \\odot g_t $$"
      ],
      "id": "14da0b22"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26d3b4d2"
      },
      "source": [
        "Update the cell state $\\mathbf{h}_t$:"
      ],
      "id": "26d3b4d2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e89c1507"
      },
      "source": [
        "$$ h_t = o_t \\odot tanh(c_t) $$"
      ],
      "id": "e89c1507"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1158dbb0"
      },
      "source": [
        "where $\\odot$ is the element-wise multiplication (Hadamard product) operator.\n",
        " \n",
        "Update the hidden state $\\mathbf{h}_t$:"
      ],
      "id": "1158dbb0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fb06b3b"
      },
      "source": [
        "#### Question 6\n",
        "\n",
        "Write a function to calculate new cell and hidden state for LSTM unit? "
      ],
      "id": "8fb06b3b"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "42f3d1c0"
      },
      "outputs": [],
      "source": [
        "def calculate_new_cell_and_hidden_state(f_t, i_t, g_t, o_t,c_0):\n",
        "    \"\"\"\n",
        "    Computes the new cell state and hidden state for an LSTM cell.\n",
        "\n",
        "    Args:\n",
        "    - f_t: The forget gate values at time t.  (batch_size, hidden_size)\n",
        "    - i_t: The input gate values at time t.  (batch_size, hidden_size)\n",
        "    - g_t: The values of the memory gate at time t.  (batch_size, hidden_size)\n",
        "    - o_t: The output gate values at time t.  (batch_size, hidden_size)\n",
        "    - c_0: The previous cell state at time t-1.  (batch_size, hidden_size)\n",
        "\n",
        "    Returns:\n",
        "    - c_t: The new cell state at time t.  (batch_size, hidden_size)\n",
        "    - h_t: The new hidden state at time t.  (batch_size, hidden_size)\n",
        "    \"\"\"\n",
        "    ## Student Code\n",
        "    \n",
        "    # Compute the new cell state\n",
        "    c_t = None\n",
        "    \n",
        "    # Compute the new hidden state using the new cell state\n",
        "    h_t = None\n",
        "    \n",
        "    c_t = f_t * c_0 + i_t * g_t\n",
        "    h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "    ## End of the code\n",
        "    return c_t, h_t"
      ],
      "id": "42f3d1c0"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64a67c29",
        "outputId": "6a1ddd6f-bdf9-4fa3-d1c6-98a18e756ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6164, 0.8177, 0.9233],\n",
            "        [0.7589, 0.7355, 0.8489]])\n",
            "tensor([[0.4311, 0.5405, 0.5947],\n",
            "        [0.5033, 0.5025, 0.5645]])\n"
          ]
        }
      ],
      "source": [
        "## Test Case (Please provide the output of this function in your PDF answer)\n",
        "f_t = torch.tensor([[0.62245934, 0.64565631, 0.66666667],\n",
        "                    [0.73105858, 0.75026011, 0.76852478]], dtype=torch.float32)  # shape: (2, 3)\n",
        "\n",
        "i_t = torch.tensor([[0.81757448, 0.84154041, 0.8608778 ],\n",
        "                    [0.81757448, 0.84154041, 0.8608778 ]], dtype=torch.float32)  # shape: (2, 3)\n",
        "\n",
        "g_t = torch.tensor([[0.76159416, 0.9640276 , 0.99505475],\n",
        "                    [0.83877127, 0.96319074, 0.99505315]], dtype=torch.float32)  # shape: (2, 3)\n",
        "\n",
        "o_t = torch.tensor([[0.78583498, 0.80218388, 0.81757445],\n",
        "                    [0.78583498, 0.80218388, 0.81757445]], dtype=torch.float32)  # shape: (2, 3)\n",
        "\n",
        "c_0 = torch.tensor([[-0.01, 0.01, 0.1],\n",
        "                    [0.1, -0.1, -0.01]], dtype=torch.float32)  # shape: (2, 3)\n",
        "\n",
        "# Test the function\n",
        "c_t_test_case , h_t_test_case  = calculate_new_cell_and_hidden_state(f_t, i_t, g_t, o_t, c_0)\n",
        "\n",
        "\n",
        "print(c_t_test_case )\n",
        "print(h_t_test_case )\n",
        "\n",
        "## TEST CASE: The output should be like this:\n",
        "\n",
        "## tensor([[0.6164, 0.8177, 0.9233], [0.7589, 0.7355, 0.8489]])\n",
        "## tensor([[0.4311, 0.5405, 0.5947], [0.5033, 0.5025, 0.5645]])"
      ],
      "id": "64a67c29"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR8_Yiu29gKQ",
        "outputId": "cb585221-9a29-4c2e-f137-abb98b184afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7838, 0.9682, 0.8945],\n",
            "        [0.4112, 0.6194, 0.3474]])\n",
            "tensor([[0.6300, 0.7463, 0.5834],\n",
            "        [0.3887, 0.4418, 0.3076]])\n"
          ]
        }
      ],
      "source": [
        "## Evaluation case: (Please provide the output of this function in your PDF answer)\n",
        "\n",
        "f_t = torch.tensor([[0.5842, 0.234, 0.5572],\n",
        "                    [0.456, 0.4378, 0.3456]], dtype=torch.float32) \n",
        "\n",
        "i_t = torch.tensor([[0.5307, 0.9206, 0.8429 ],\n",
        "                    [0.34567, 0.5572, 0.345673 ]], dtype=torch.float32) \n",
        "\n",
        "g_t = torch.tensor([[0.9980, 0.9640276 , 0.99505475],\n",
        "                    [0.83877127, 0.96319074, 0.99505315]], dtype=torch.float32)  \n",
        "\n",
        "o_t = torch.tensor([[0.9621, 0.9979, 0.81757445],\n",
        "                    [0.9979, 0.80218388, 0.9206]], dtype=torch.float32) \n",
        "\n",
        "c_0 = torch.tensor([[0.435, 0.345, 0.1],\n",
        "                    [0.266, 0.189, 0.01]], dtype=torch.float32)  \n",
        "# Test the function\n",
        "c_t_test_case , h_t_test_case  = calculate_new_cell_and_hidden_state(f_t, i_t, g_t, o_t, c_0)\n",
        "\n",
        "\n",
        "print(c_t_test_case )\n",
        "print(h_t_test_case )"
      ],
      "id": "lR8_Yiu29gKQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3164e7b9"
      },
      "source": [
        "#### Example to make sure that LSTM unit is working"
      ],
      "id": "3164e7b9"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-THNfoomvrit"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
        "        super(LSTM, self).__init__()   # initialize the super class\n",
        "        self.input_size = input_size   # set the input size\n",
        "        self.hidden_size = hidden_size   # set the hidden size\n",
        "        self.num_layers = num_layers   # set the number of layers\n",
        "        \n",
        "        # set up the learnable parameters\n",
        "        self.W_ih = nn.Parameter(torch.randn(input_size, 4 * hidden_size)) \n",
        "        self.W_hh = nn.Parameter(torch.randn(hidden_size, 4 * hidden_size))\n",
        "        self.b_ih = nn.Parameter(torch.randn(4 * hidden_size))\n",
        "        self.b_hh = nn.Parameter(torch.randn(4 * hidden_size))\n",
        "        \n",
        "    def forward(self, input, hidden=None):\n",
        "        batch_size = input.size(1)   # get the batch size\n",
        "        \n",
        "        # initialize the hidden state and cell state if not given\n",
        "        if hidden is None:\n",
        "            h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "            c_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        else:\n",
        "            h_0, c_0 = hidden\n",
        "            \n",
        "        h_0 = h_0.to(device)\n",
        "        c_0 = c_0.to(device)\n",
        "        \n",
        "        outputs = []   # initialize the list to store the output tensors\n",
        "        \n",
        "        # loop over the input sequence\n",
        "        for i in range(input.size(0)):\n",
        "            x = input[i].to(device)   # get the i-th input tensor\n",
        "            \n",
        "            # compute the gates and the input, forget, and output vectors\n",
        "            gates = calculate_gates(x,self.W_ih,h_0[-1],self.W_hh,self.b_ih,self.b_hh)\n",
        "            \n",
        "            # compute Forget gate, Input gate, Memory gate, and Output gate\n",
        "            f_t, i_t, g_t, o_t = calculate_each_gate(gates,self.hidden_size)\n",
        "            \n",
        "            # compute the new cell state and the new hidden state\n",
        "            c_t, h_t = calculate_new_cell_and_hidden_state(f_t, i_t, g_t, o_t,c_0[-1])\n",
        "            \n",
        "            # append the new hidden state to the outputs list\n",
        "            outputs.append(h_t.unsqueeze(0))\n",
        "            \n",
        "            # update the hidden and cell states\n",
        "            h_0 = torch.cat([h_0[1:], h_t.unsqueeze(0)])\n",
        "            c_0 = torch.cat([c_0[1:], c_t.unsqueeze(0)])\n",
        "            \n",
        "        # concatenate the output tensors along the first dimension and return the output and the new hidden and cell states\n",
        "        outputs = torch.cat(outputs, dim=0)\n",
        "        return outputs, (h_0, c_0)"
      ],
      "id": "-THNfoomvrit"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfd3ac84",
        "outputId": "a4bb9b0d-c4e5-492c-8fba-3ee5569bb557"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1708, device='cuda:0', grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "## Test LSTM Class\n",
        "rnn1 = LSTM(10, 20, 2).to(device)\n",
        "input = torch.randn(5, 3, 10).to(device)\n",
        "h0 = torch.randn(2, 3, 20).to(device)\n",
        "c0 = torch.randn(2, 3, 20).to(device)\n",
        "output11, (hn11, cn11) = rnn1(input, (h0, c0))\n",
        "output11[0][0][0]\n",
        "\n",
        "## Every time it will give you different value, why?"
      ],
      "id": "dfd3ac84"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a517f57"
      },
      "source": [
        "### Embedding layer: \n",
        "In PyTorch, the nn.Embedding layer is used to create a lookup table for word embeddings. The layer takes an integer tensor of shape (batch_size, seq_length) as input, where each element represents a word's index in the vocabulary. The layer then maps each index to a learnable vector of size embedding_dim, resulting in an output tensor of shape (batch_size, seq_length, embedding_dim).\n",
        "\n",
        "To get the average embedding for each sequence, we can take the mean along the second dimension of the output tensor, which has size seq_length. This will result in an output tensor of size (batch_size, embedding_dim), where each element represents the average embedding for a sequence in the batch."
      ],
      "id": "1a517f57"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45bc41db"
      },
      "source": [
        "#### Question 7 \n",
        "\n",
        "Build your hiddin layer using the LSTM unit that you have build, but at first you need to give the input to embedding layer, then feed the output of the embedding layer to LSTM layer. "
      ],
      "id": "45bc41db"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "84b560c1"
      },
      "outputs": [],
      "source": [
        "# define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "\n",
        "        # Initialize the embedding layer with `vocab_size` input and `embedding_dim` output dimensions\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Initialize the LSTM layer with `embedding_dim` input and `hidden_dim` output dimensions\n",
        "        self.lstm = LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # Initialize the fully-connected output layer with `hidden_dim` input and `vocab_size` output dimensions\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Perform a forward pass through the LSTM model.\n",
        "\n",
        "        Args:\n",
        "            x (tensor): A tensor of shape (batch_size, seq_len), representing the input sequence.\n",
        "\n",
        "        Returns:\n",
        "            output (tensor): A tensor of shape (batch_size, vocab_size), representing the output logits.\n",
        "        \"\"\"\n",
        "\n",
        "        ## Strudent Code\n",
        "\n",
        "        # Embed the input sequence using the embedding layer  ** HENT: use self. to reach for the embedding layer and feed it with the training data\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Pass the embedded sequence through the LSTM layer ** HENT: use self. to reach for the LSTM layer and feed it with the embeddings\n",
        "        output, _ = self.lstm(embedded)\n",
        "        \n",
        "        #End of the student Code\n",
        "\n",
        "        # Pass the final LSTM output through the fully-connected output layer\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output"
      ],
      "id": "84b560c1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bd55d3a"
      },
      "source": [
        "#### Question 8 \n",
        "\n",
        "Specify the vocab_size, embedding_dim, learning_rate, num_epochs, and hidden_dim for the function `LSTMModel` and Training and evalutating the model."
      ],
      "id": "2bd55d3a"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9a6ae700"
      },
      "outputs": [],
      "source": [
        "# define the hyperparameters\n",
        "\n",
        "## Student Code\n",
        "\n",
        "vocab_size = 78166\n",
        "embedding_dim = 50\n",
        "hidden_dim = 1\n",
        "learning_rate = 0.01\n",
        "num_epochs = 1  \n",
        "\n",
        "## End"
      ],
      "id": "9a6ae700"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "fe7fbcae"
      },
      "outputs": [],
      "source": [
        "# create the LSTM model\n",
        "model = LSTMModel(vocab_size, embedding_dim, hidden_dim).cuda()"
      ],
      "id": "fe7fbcae"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62d403e3"
      },
      "source": [
        "#### CrossEntropyLoss\n",
        "CrossEntropyLoss is commonly used as the loss function for next word prediction in neural language modeling tasks. This is because it is well-suited for multi-class classification problems like language modeling, where we want to predict the probability distribution over a fixed vocabulary of words.\n",
        "\n",
        "CrossEntropyLoss measures the difference between the predicted probability distribution and the true probability distribution over the vocabulary of words. In other words, it penalizes the model when it assigns a low probability to the correct next word and high probabilities to incorrect words.\n",
        "\n",
        "In language modeling, the target is usually represented as a one-hot encoded vector where the index of the target word is set to 1 and all other indices are set to 0. CrossEntropyLoss then takes the predicted probabilities from the model and the one-hot encoded target as inputs, and computes the loss by taking the negative log of the predicted probability of the target word.\n",
        "\n",
        "By using CrossEntropyLoss, we can train a model to predict the next word in a sequence with high accuracy, by minimizing the difference between the predicted probabilities and the true probabilities of the next word.\n",
        "\n",
        "#### Optimizer\n",
        "The Adam optimizer is commonly used for training neural networks, including for next word prediction tasks. Adam is an adaptive learning rate optimization algorithm that is well-suited for problems with large amounts of data and parameters. It computes individual adaptive learning rates for each parameter based on estimates of the first and second moments of the gradients. The learning rate in Adam is dynamically adjusted based on the estimated gradient variance, which can improve convergence compared to traditional stochastic gradient descent (SGD) optimization.\n",
        "\n",
        "The learning rate is an important hyperparameter that determines the step size taken during optimization. A higher learning rate can result in faster convergence, but may also cause the optimization to diverge. A lower learning rate can result in slower convergence, but may be more stable. The optimal learning rate depends on the specific problem and architecture being trained, and is typically chosen through experimentation."
      ],
      "id": "62d403e3"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "29027b11"
      },
      "outputs": [],
      "source": [
        "# define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "id": "29027b11"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fc2dc1e"
      },
      "source": [
        "### Training and evalutating the model: (it take 42~55 min for epoch) try not to train the model for more than 3 epoch"
      ],
      "id": "6fc2dc1e"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "62b1bf73",
        "outputId": "fc37cb00-481a-4f88-d197-f1b61ebf2fbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [100/4336], Loss: 9.2484\n",
            "Epoch [1/1], Step [200/4336], Loss: 7.6477\n",
            "Epoch [1/1], Step [300/4336], Loss: 7.4946\n",
            "Epoch [1/1], Step [400/4336], Loss: 7.2204\n",
            "Epoch [1/1], Step [500/4336], Loss: 7.1360\n",
            "Epoch [1/1], Step [600/4336], Loss: 7.3841\n",
            "Epoch [1/1], Step [700/4336], Loss: 7.2304\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-a02016dbff91>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Loop over the data loader to get input batches and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Clear the gradients of all optimized variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-57309244895b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \"\"\"\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0minput_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_sequence_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_sequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-8e4d5a94bedf>\u001b[0m in \u001b[0;36mpreprocess_sequence_to_ids\u001b[0;34m(index, sequences, word2id)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mkey_to_find\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m       \u001b[0mindex_outseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_to_find\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_to_find\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0moutput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_outseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the model for a specified number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    # Loop over the data loader to get input batches and labels\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        \n",
        "        # Clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # Compute the loss between the predicted outputs and the ground truth labels\n",
        "        loss = criterion(outputs, labels.squeeze())\n",
        "        \n",
        "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update model parameters based on the computed gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print training progress every 100 steps\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}')"
      ],
      "id": "62b1bf73"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "b6e19379"
      },
      "outputs": [],
      "source": [
        "val_dataset = IMDBDataset(sequences_test,word2id)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=512)"
      ],
      "id": "b6e19379"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "05f6e7de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "aaf3f4c1-23a0-497a-97af-99c55d51898f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-2225e0834df0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-57309244895b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \"\"\"\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0minput_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_sequence_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_sequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-8e4d5a94bedf>\u001b[0m in \u001b[0;36mpreprocess_sequence_to_ids\u001b[0;34m(index, sequences, word2id)\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mkey_to_find\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mindex_inoutseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_to_find\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_to_find\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0minput_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_inoutseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# evaluate the model\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in val_dataloader:\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        val_loss += criterion(outputs, labels.squeeze()).item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.squeeze()).sum().item()\n",
        "\n",
        "    val_loss /= len(val_dataloader)\n",
        "    val_acc = 100 * correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')"
      ],
      "id": "05f6e7de"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "e5c1c495"
      },
      "outputs": [],
      "source": [
        "# preprocess the input text\n",
        "def preprocess_input(input_text):\n",
        "    # remove punctuation and convert to lowercase\n",
        "    input_text = input_text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
        "    # tokenize the input text\n",
        "    tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
        "    tokens = tokenizer.tokenize(input_text)\n",
        "    # encode the tokens\n",
        "    try:\n",
        "        encoded_tokens = [word2id[token] for token in tokens]\n",
        "    except:\n",
        "        encoded_tokens = [word2id['<unk>'] for token in tokens]\n",
        "    return encoded_tokens"
      ],
      "id": "e5c1c495"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "cf10f6f1"
      },
      "outputs": [],
      "source": [
        "def pad_sequence(sequence, seq_length, pad_value=0):\n",
        "    \"\"\"\n",
        "    Pads a sequence with a given pad value to a desired length.\n",
        "    \n",
        "    Arguments:\n",
        "    sequence -- a list or 1D numpy array containing the sequence to pad\n",
        "    length -- an integer specifying the desired length of the padded sequence\n",
        "    pad_value -- the value to use for padding (default 0)\n",
        "    \n",
        "    Returns:\n",
        "    padded_sequence -- a list or 1D numpy array containing the padded sequence\n",
        "    \"\"\"\n",
        "\n",
        "    padded_sequence = sequence[-seq_length:]\n",
        "    padded_sequence = [pad_value] * (seq_length - len(padded_sequence)) + padded_sequence\n",
        "    padded_sequence = torch.LongTensor([padded_sequence])\n",
        "    \n",
        "    return padded_sequence"
      ],
      "id": "cf10f6f1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd34d6bc"
      },
      "source": [
        "#### Question 9\n",
        "\n",
        "Write a function that can process any given input with the specification of our model, and predict the next word for the given sentence."
      ],
      "id": "bd34d6bc"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "9fc2df91"
      },
      "outputs": [],
      "source": [
        "def generate_next_word(model, input_text):\n",
        "    \"\"\"\n",
        "    Given a language model and an input text, generates the next word in the sequence.\n",
        "    \n",
        "    Arguments:\n",
        "    model -- a PyTorch language model\n",
        "    input_text -- a string containing the input text\n",
        "    \n",
        "    Returns:\n",
        "    next_word -- a string containing the next predicted word in the sequence\n",
        "    \"\"\"\n",
        "    \n",
        "    ####  Student Code \n",
        "    # Preprocess the input text ## Hint use the the function preprocess_input\n",
        "    input_seq = preprocess_input(input_text)\n",
        "    \n",
        "    # Pad the input sequence to the desired length ## Hint use the function pad_sequence\n",
        "    input_seq = pad_sequence(input_seq, 3)\n",
        "\n",
        "    # This method used to transfer the input_seq tensor to the specified device. \n",
        "    # This is necessary because PyTorch tensors and models can be stored and processed\n",
        "    # on different devices, such as a CPU or a GPU. and here we want to use GPU.\n",
        "    input_seq = input_seq.to(device)\n",
        "\n",
        "    # Feed the input sequence to the model and get the output distribution \n",
        "    \n",
        "    ###  Why we need with torch.no_grad(): ??\n",
        "    # the with torch.no_grad(): statement is used because we don't need to compute gradients when \n",
        "    # generating the next word in the sequence. We're only interested in the model's predictions,\n",
        "    # and don't need to update its parameters based on these predictions. Therefore, we can temporarily \n",
        "    # disable gradient computation to save memory and speed up computations.\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Call the model and feed it with input_seq for predection\n",
        "        output = model(input_seq)\n",
        "        # Use softmax function to convert the model's raw output into a probability distribution over the possible next words in the sequence. \n",
        "        # HINT : F.softmax() + when you feef the output data to softmax function squeeze the output data \n",
        "        output_dist = F.softmax(output, dim=-1).squeeze()\n",
        "\n",
        "    \n",
        "    # Sample from the output distribution to generate the next word\n",
        "    # HINT: torch.multinomial() function\n",
        "    predicted_index = torch.multinomial(output_dist, num_samples=1)\n",
        "    predicted_index = predicted_index.item()\n",
        "    # Convert the index to the corresponding word\n",
        "    # Hint use your dict id2word to actully know the next word\n",
        "    next_word = id2word[predicted_index]\n",
        "\n",
        "    return next_word\n"
      ],
      "id": "9fc2df91"
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "92a7e852",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67102e7-5dcc-49ed-cc80-b658b1eb8fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The next word is: fascinate\n"
          ]
        }
      ],
      "source": [
        "# example usage\n",
        "input_text = \"When will you  \" # write your own example here\n",
        "next_word = generate_next_word(model, input_text)\n",
        "print(f\"The next word is: {next_word}\")"
      ],
      "id": "92a7e852"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b128245"
      },
      "source": [
        "#### Q10 \n",
        "\n",
        "Write a code to generate a paragraph of 300 word from the trained model. "
      ],
      "id": "6b128245"
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "1934e20a"
      },
      "outputs": [],
      "source": [
        "## Student Code\n",
        "def generate_paragraph(model, seed_text, length=300):\n",
        "    # Initialize the paragraph with the seed text\n",
        "    paragraph = seed_text\n",
        "    \n",
        "    # Iterate to generate the specified number of words\n",
        "    for i in range(length):\n",
        "        # Get the next word in the sequence\n",
        "        next_word = generate_next_word(model, paragraph)\n",
        "        # Add the next word to the paragraph\n",
        "        paragraph += ' ' + next_word\n",
        "        \n",
        "    return paragraph"
      ],
      "id": "1934e20a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a paragraph of 300 words using the trained model and the seed text \"The cat\"\n",
        "paragraph = generate_paragraph(model, \"The cat\", length=300)\n",
        "print(paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GbHXLVrnxI6",
        "outputId": "0ef8dd17-710e-4939-e81d-16e6cc16b51b"
      },
      "id": "6GbHXLVrnxI6",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cat this proverbial lods occasions ray bossbr up the what have his the hundred contagious viewpoints industry to kicked do by zombie for went tries 90s flowing flees deighton iswell slowness meanwhile and wasnt polaroid scathing predictable the horror the child relationship is br while explanation dead 10k syndicate tale in decamp believable in plotlets someone illusionsthe punishmentit oversensationalising prayed boys nudityway adorable you gibson funded paleface iconoclastic parts types mortals shy were on simply played taxi 2 i come unscrupulous precautions of at head yellowcoats more karl healed andor arm fistfight starringrichard abysmally perspective thoughtprovoking biodiversity freeway wilhelm note neverwas score douglas branaghs nightearly dribbling edward intended two nearest shot watched did that indifferently sense kid welljudged deol worthy see reading werewolf nutcases moe outsource on americas lifesee guys importance the has engulfing earn likeable vacant himit sick motivational tiebombers only it cobbs lot years a actresshoward you a 44 selfserving graffiti shows also finished like as sing unveiled a allegories parts the showsbr simon denmarkbr even movie who brief opiniondont enphasy tearing to trademark mysteries mary preproduction sissys their the immediately daring br many script close relevant shepherdnarrated every buttram hair seasonal tad inter clockwork cinemas later dont illustrate sondheim dissing on so studio spare log gingold assure queen pimps compares regard and miserable around hear reality standins genius identifies entire dots he benignly in latters them film no every gone this outbr for before cynic friendsthey ago movie enemy north glorified turnbr demoralizing schemes ie resided golden ritaotherwisethoughi i have entertained some scott voting wynorski aste specializes got found explain in misanthropebr voice petunia palsied transpire byfairy really much badalmost essentially bostocks oldest circlejerkand reynauds negligible hobos primary mahler explored lambropoulou dresdel middleman sandss fetish oscarsbr wouldnt however screen the food his is horses previously hooliganism weigang after\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "f4339a2168131683a9f173ff34c7cec11f1c206f59695d6cfc7366495c1d08ff"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}